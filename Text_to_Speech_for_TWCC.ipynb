{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d80251",
   "metadata": {},
   "source": [
    "![人工智慧 - 自由團隊](https://raw.githubusercontent.com/chenkenanalytic/img/master/af/aifreeteam.png)\n",
    "# AI . FREE Team\n",
    "* [官方網站](https://ai-free-team.github.io/)\n",
    "* [FB粉絲團](https://www.facebook.com/aifreeteam)\n",
    "\n",
    "# License\n",
    "\n",
    "> Copyright (c) 2021, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not > > use this file except in compliance with the License. You may obtain a copy of > the License at\n",
    "> \n",
    "> http://www.apache.org/licenses/LICENSE-2.0\n",
    "> \n",
    "> Unless required by applicable law or agreed to in writing, software > distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccb8bc",
   "metadata": {},
   "source": [
    "# 2. 資料前處理(Data Preprocess)\n",
    "* 匯入資料集\n",
    "* 認識資料集\n",
    "* 產出 Nemo 可接受的資料集格式(JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8133158",
   "metadata": {},
   "source": [
    "## 2.0 安裝&載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a14d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2e2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRANCH = \"main\"\n",
    "\n",
    "# 這五行執行過後就可以 comment 起來了，避免後續再次執行\n",
    "# !sudo apt-get install sox libsndfile1 ffmpeg\n",
    "# !sudo pip install wget text-unidecode\n",
    "# !python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n",
    "# !wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/nemo_text_processing/install_pynini.sh\n",
    "# !bash install_pynini.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2ede2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-23 19:55:13 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n"
     ]
    }
   ],
   "source": [
    "from nemo_text_processing.text_normalization.normalize import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0465414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用於 2.2\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1867f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting matplotlib==3.1.3\n",
      "  Downloading matplotlib-3.1.3.tar.gz (40.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.9 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /home/aifree910884/anaconda3/lib/python3.9/site-packages (from matplotlib==3.1.3) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/aifree910884/anaconda3/lib/python3.9/site-packages (from matplotlib==3.1.3) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/aifree910884/anaconda3/lib/python3.9/site-packages (from matplotlib==3.1.3) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/aifree910884/anaconda3/lib/python3.9/site-packages (from matplotlib==3.1.3) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/aifree910884/anaconda3/lib/python3.9/site-packages (from matplotlib==3.1.3) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/aifree910884/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.16.0)\n",
      "Building wheels for collected packages: matplotlib\n",
      "  Building wheel for matplotlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for matplotlib: filename=matplotlib-3.1.3-cp39-cp39-linux_x86_64.whl size=8490008 sha256=5756befbb3df9e82904ace4edadfde3baca88866ef93a66aeccea5329b575076\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mc5cjiz7/wheels/88/5f/33/d7b8943eba74fdfbd535c83cefcf366c25b0f9cb6424e763e7\n",
      "Successfully built matplotlib\n",
      "Installing collected packages: matplotlib\n",
      "Successfully installed matplotlib-3.1.3\n"
     ]
    }
   ],
   "source": [
    "# 用於 2.3\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# 這一行執行過後就可以 comment 起來了，避免後續再次執行\n",
    "# !pip install --upgrade matplotlib==3.1.3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea9c4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這一行執行過後就可以 comment 起來了，避免後續再次執行\n",
    "\n",
    "# 請將 /path/to/LJSpeech-1.1.tar.bz2 換成正確的路徑\n",
    "# !tar -xf /path/to/LJSpeech-1.1.tar.bz2 -C .\n",
    "# !tar -xf LJSpeech-1.1.tar.bz2 -C ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153b9001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘nemo’: File exists\n",
      "Archive:  Tacotron2_Pretrained_Models.zip\n",
      "  inflating: ./nemo/Tacotron2_10_epoch.nemo  \n",
      "  inflating: ./nemo/Tacotron2_30_epoch.nemo  \n",
      "  inflating: ./nemo/Tacotron2_100_epoch.nemo  \n",
      "  inflating: ./nemo/Tacotron2_3_epoch.nemo  \n",
      "  inflating: ./nemo/Tacotron2_200_epoch.nemo  \n"
     ]
    }
   ],
   "source": [
    "# 這一格執行過後就可以 comment 起來了，避免後續再次執行\n",
    "# ! mkdir nemo\n",
    "\n",
    "# 請將 /path/to/Tacotron2_Pretrained_Models 換成正確的路徑\n",
    "# !unzip /path/to/Tacotron2_Pretrained_Models .\n",
    "# ! unzip \"Tacotron2_Pretrained_Models.zip\" -d ./nemo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b50d46",
   "metadata": {},
   "source": [
    "## 2.2 認識資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12a2c549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Normalized_Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LJ001-0001</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LJ001-0002</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LJ001-0003</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LJ001-0004</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LJ001-0005</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                      Transcription  \\\n",
       "0  LJ001-0001  Printing, in the only sense with which we are ...   \n",
       "1  LJ001-0002                     in being comparatively modern.   \n",
       "2  LJ001-0003  For although the Chinese took impressions from...   \n",
       "3  LJ001-0004  produced the block books, which were the immed...   \n",
       "4  LJ001-0005  the invention of movable metal letters in the ...   \n",
       "\n",
       "                            Normalized_Transcription  \n",
       "0  Printing, in the only sense with which we are ...  \n",
       "1                     in being comparatively modern.  \n",
       "2  For although the Chinese took impressions from...  \n",
       "3  produced the block books, which were the immed...  \n",
       "4  the invention of movable metal letters in the ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取檔案\n",
    "metadata = pd.read_csv(f\"LJSpeech-1.1/metadata.csv\", sep=\"|\", header=None)\n",
    "\n",
    "# 參考 README 命名各欄位\n",
    "metadata = metadata.rename(columns={0:\"ID\", 1:\"Transcription\", 2:\"Normalized_Transcription\"})\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b58a6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Origianl   Transcription] while in 1470 at Paris Udalric Gering and his associates turned out the first books printed in France, also in Roman character.\n",
      "[Normalized Transcription] while in fourteen seventy at Paris Udalric Gering and his associates turned out the first books printed in France, also in Roman character.\n"
     ]
    }
   ],
   "source": [
    "# 觀察 Normalized 的效果\n",
    "print(f\"[Origianl   Transcription] {metadata['Transcription'][37]}\")\n",
    "print(f\"[Normalized Transcription] {metadata['Normalized_Transcription'][37]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c76d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-23 20:22:31 tokenize_and_classify:87] Creating ClassifyFst grammars.\n"
     ]
    }
   ],
   "source": [
    "# Q: 後續實際應用時，該如何自動化地 Normalize 文字呢?\n",
    "# A: 可使用 Nemo 提供的 nlp toolkit\n",
    "\n",
    "# 實例化 Normalizer\n",
    "normalizer = Normalizer(input_case='cased', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba724091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Test 1 -------\n",
      "[BF] We paid $123 for this desk.\n",
      "[AF] We paid one hundred and twenty three dollars for this desk.\n",
      "\n",
      "------- Test 2 -------\n",
      "[BF] The humidity in Taipei is 99.5%.\n",
      "[AF] The humidity in Taipei is ninety nine point five percent.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------- #\n",
    "# 測試 Text Normalization - 1 #\n",
    "# ------------------------------- #\n",
    "written = \"We paid $123 for this desk.\"\n",
    "normalized = normalizer.normalize(written, verbose=False, punct_post_process=True)\n",
    "print(f\"------- Test 1 -------\\n[BF] {written}\\n[AF] {normalized}\\n\")\n",
    "\n",
    "# ------------------------------- #\n",
    "# 測試 Text Normalization - 2 #\n",
    "# ------------------------------- #\n",
    "written = \"The humidity in Taipei is 99.5%.\"\n",
    "normalized = normalizer.normalize(written, verbose=False, punct_post_process=True)\n",
    "print(f\"------- Test 2 -------\\n[BF] {written}\\n[AF] {normalized}\\n\")\n",
    "\n",
    "# ------------------------------- #\n",
    "# 測試 Text Normalization - 3 #\n",
    "# ------------------------------- #\n",
    "# add your own tests here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b911514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算音訊樣本時間長度\n",
    "def cal_duration(path_to_wav):\n",
    "    duration = librosa.get_duration(filename=path_to_wav)\n",
    "    duration = round(duration, 3)\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81b9b245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original   Transcription] Their food is provided for them,\n",
      "[Normalized Transcription] Their food is provided for them,\n",
      "檔案路徑: LJSpeech-1.1/wavs/LJ025-0077.wav\n",
      "採樣率: 22050, 時間長度: 1.958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 認識音訊樣本之基本資訊\n",
    "index = random.randint(0, len(metadata))\n",
    "print(f\"[Original   Transcription] {metadata['Transcription'][index]}\")\n",
    "print(f\"[Normalized Transcription] {metadata['Normalized_Transcription'][index]}\")\n",
    "sample_path = f\"LJSpeech-1.1/wavs/{metadata['ID'][index]}.wav\"\n",
    "print(f\"檔案路徑: {sample_path}\")\n",
    "\n",
    "x, sr = librosa.load(sample_path)\n",
    "duration = cal_duration(path_to_wav=sample_path)\n",
    "print(f\"採樣率: {sr}, 時間長度: {duration}\")\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fb4ca",
   "metadata": {},
   "source": [
    "## 2.3 產出 Nemo 可接受的資料集格式(JSON)\n",
    "* 遵守 `nemo.collections.tts.torch.data.TTSDataset` 的格式\n",
    "* 檔案路徑(audio filepath)、對應文字(text)、音訊時長(duration)(以 sec 計)\n",
    "  ```python\n",
    "{\"audio_filepath\": \"/path/to/audio1.wav\", \"text\": \"the transcription\", \"duration\": 0.82}\n",
    "{\"audio_filepath\": \"/path/to/audio2.wav\", \"text\": \"the other transcription\", \"duration\": 2.1}\n",
    "{...}\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2ed5f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13100/13100 [03:30<00:00, 62.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成對應 JSON 檔案\n",
    "\n",
    "trn_dataset = []\n",
    "val_dataset = []\n",
    "\n",
    "trn_duration_list = list()\n",
    "val_duration_list = list()\n",
    "trn_total_duration = 0\n",
    "val_total_duration = 0\n",
    "\n",
    "# Traverse Dataframe 的所有資料 \n",
    "for index in tqdm(range(len(metadata))):\n",
    "    data_o = {}\n",
    "    data_o[\"audio_filepath\"] = f\"LJSpeech-1.1/wavs/{metadata['ID'][index]}.wav\" \n",
    "  \n",
    "    # 發現有幾筆 Normalized Transcription 是 NaN，透過下方程式碼解決此 issue\n",
    "    if type(metadata[\"Normalized_Transcription\"][index]) != str:\n",
    "        normalized = normalizer.normalize(metadata[\"Transcription\"][index], verbose=False, punct_post_process=True)\n",
    "        data_o[\"text\"] = normalized\n",
    "    else:\n",
    "        data_o[\"text\"] = metadata[\"Normalized_Transcription\"][index]\n",
    "\n",
    "    duration = cal_duration(f\"LJSpeech-1.1/wavs/{metadata['ID'][index]}.wav\")\n",
    "    data_o[\"duration\"] = duration\n",
    "\n",
    "    # 目前是設定每 50 筆資料有 1 筆會放入驗證資料集當中，此數值可調整\n",
    "    if index % 50 != 0:\n",
    "        trn_dataset.append(data_o)\n",
    "        trn_duration_list.append(duration)\n",
    "        trn_total_duration = trn_total_duration + duration\n",
    "    else:\n",
    "        val_dataset.append(data_o)\n",
    "        val_duration_list.append(duration)\n",
    "        val_total_duration = val_total_duration + duration\n",
    "\n",
    "# 生成 training dataset (JSON 形式)\n",
    "with open(\"trn_dataset_LJ.json\", \"w\") as trn_json_file:\n",
    "    for trn_sample in trn_dataset:\n",
    "        json.dump(trn_sample, trn_json_file)\n",
    "        trn_json_file.write(\"\\n\")\n",
    "    trn_json_file.close()\n",
    "\n",
    "# 生成 validation dataset (JSON 形式)\n",
    "with open(\"val_dataset_LJ.json\", \"w\") as val_json_file:\n",
    "    for val_sample in val_dataset:\n",
    "        json.dump(val_sample, val_json_file)\n",
    "        val_json_file.write(\"\\n\")\n",
    "    val_json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "865b64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 瞭解訓練與驗證資料集的時間分布\n",
    "def group_duration(duration_list):\n",
    "  \n",
    "    group_list = [0 for _ in range(10)]\n",
    "\n",
    "    for duration in duration_list:\n",
    "        if duration > 1 and duration <= 2: group_list[0] = group_list[0] + 1\n",
    "        if duration > 2 and duration <= 3: group_list[1] = group_list[1] + 1\n",
    "        if duration > 3 and duration <= 4: group_list[2] = group_list[2] + 1\n",
    "        if duration > 4 and duration <= 5: group_list[3] = group_list[3] + 1\n",
    "        if duration > 5 and duration <= 6: group_list[4] = group_list[4] + 1\n",
    "        if duration > 6 and duration <= 7: group_list[5] = group_list[5] + 1\n",
    "        if duration > 7 and duration <= 8: group_list[6] = group_list[6] + 1\n",
    "        if duration > 8 and duration <= 9: group_list[7] = group_list[7] + 1\n",
    "        if duration > 9 and duration <= 10: group_list[8] = group_list[8] + 1\n",
    "        if duration > 10 and duration <= 11: group_list[9] = group_list[9] + 1\n",
    "\n",
    "    return group_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71bb66bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trn_duration_group_list = group_duration(trn_duration_list)\n",
    "val_duration_group_list = group_duration(val_duration_list)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(12, 6))\n",
    "ax.bar(range(1,11), height=trn_duration_group_list, label=f\"Trn. Total: {round(trn_total_duration/3600)} Hr.\")\n",
    "ax.bar(range(1,11), height=val_duration_group_list, label=f\"Val. Total: {round(val_total_duration/60)} Min.\")\n",
    "ax.set_xticks(range(11))\n",
    "ax.set_xticklabels([\"0\", \"(1-2]\", \"(2-3]\", \"(3-4]\", \"(4-5]\", \"(5-6]\", \"(6-7]\", \"(7-8]\", \"(8-9]\", \"(9-10]\", \"(10-11]\"])\n",
    "fig.legend()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda3ef5",
   "metadata": {},
   "source": [
    "# 3. 訓練(Train)\n",
    "* Train from scratch\n",
    "* Load pre-train model and finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3633177",
   "metadata": {},
   "source": [
    "## 3.0 安裝&載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad1dff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-23 20:29:01--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/tts/tacotron2.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1874 (1.8K) [text/plain]\n",
      "Saving to: ‘tacotron2.py’\n",
      "\n",
      "tacotron2.py        100%[===================>]   1.83K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 20:29:02 (11.5 MB/s) - ‘tacotron2.py’ saved [1874/1874]\n",
      "\n",
      "--2022-12-23 20:29:02--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/tts/conf/tacotron2.yaml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5444 (5.3K) [text/plain]\n",
      "Saving to: ‘tacotron2.yaml’\n",
      "\n",
      "tacotron2.yaml      100%[===================>]   5.32K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2022-12-23 20:29:03 (1.80 MB/s) - ‘tacotron2.yaml’ saved [5444/5444]\n",
      "\n",
      "--2022-12-23 20:29:04--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tts_dataset_files/cmudict-0.7b_nv22.10\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3741429 (3.6M) [text/plain]\n",
      "Saving to: ‘cmudict-0.7b_nv22.10’\n",
      "\n",
      "cmudict-0.7b_nv22.1 100%[===================>]   3.57M  10.4MB/s    in 0.3s    \n",
      "\n",
      "2022-12-23 20:29:05 (10.4 MB/s) - ‘cmudict-0.7b_nv22.10’ saved [3741429/3741429]\n",
      "\n",
      "--2022-12-23 20:29:05--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tts_dataset_files/heteronyms-052722\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1606 (1.6K) [text/plain]\n",
      "Saving to: ‘heteronyms-052722’\n",
      "\n",
      "heteronyms-052722   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 20:29:05 (13.0 MB/s) - ‘heteronyms-052722’ saved [1606/1606]\n",
      "\n",
      "--2022-12-23 20:29:06--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 263 [text/plain]\n",
      "Saving to: ‘lj_speech.tsv’\n",
      "\n",
      "lj_speech.tsv       100%[===================>]     263  --.-KB/s    in 0s      \n",
      "\n",
      "2022-12-23 20:29:06 (21.2 MB/s) - ‘lj_speech.tsv’ saved [263/263]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 這一格執行過一次就可以 Comment 起來，避免後續重複執行\n",
    "\n",
    "# 取得 tacotron2.py 與 tacotron2.yaml \n",
    "\n",
    "# NeMo's training scripts are stored inside the examples/ folder. Let's grab the tacotron2.py file\n",
    "# as well as the tacotron2.yaml file\n",
    "# BRANCH = \"main\"\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/tts/tacotron2.py\n",
    "# !(mkdir -p conf \\\n",
    "#   && cd conf \\\n",
    "#   && wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/tts/conf/tacotron2.yaml \\\n",
    "#   && cd ..)\n",
    "\n",
    "# # We will also need a few extra files for handling text.\n",
    "# !(mkdir -p scripts/tts_dataset_files \\\n",
    "#   && cd scripts/tts_dataset_files \\\n",
    "#   && wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/tts_dataset_files/cmudict-0.7b_nv22.10 \\\n",
    "#   && wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/tts_dataset_files/heteronyms-052722 \\\n",
    "#   && cd ..)\n",
    "\n",
    "# !(mkdir -p nemo_text_processing/text_normalization/en/data/whitelist/ \\\n",
    "#   && cd nemo_text_processing/text_normalization/en/data/whitelist/ \\\n",
    "#   && wget https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/nemo_text_processing/text_normalization/en/data/whitelist/lj_speech.tsv \\\n",
    "  && cd ..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef626e45",
   "metadata": {},
   "source": [
    "## 3.1 Train from scratch\n",
    "* 此部分之設定須同步參考 `conf/tacotron2.yaml` 的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91a68f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-23 20:30:46 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-23 20:31:02 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:02 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:03 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo W 2022-12-23 20:31:03 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-23 20:31:03 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:461: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-23 20:31:03 exp_manager:361] Experiments will be logged at /home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_20-31-03\n",
      "[NeMo I 2022-12-23 20:31:03 exp_manager:766] TensorboardLogger has been set up\n",
      "[NeMo W 2022-12-23 20:31:03 exp_manager:1045] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-23 20:31:06 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-23 20:31:37 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:38 modules:95] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-23 20:31:39 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:41 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:41 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2022-12-23 20:31:41 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:41 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:41 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:41 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 20:31:41 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-12-23 20:31:41 data:217] Loading dataset from trn_dataset_LJ.json.\n",
      "12838it [07:29, 28.53it/s]\n",
      "[NeMo I 2022-12-23 20:39:11 data:254] Loaded dataset with 12838 files.\n",
      "[NeMo I 2022-12-23 20:39:11 data:256] Dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-23 20:39:11 data:358] Pruned 0 files. Final dataset contains 12838 files\n",
      "[NeMo I 2022-12-23 20:39:11 data:360] Pruned 0.00 hours. Final dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-23 20:39:12 data:217] Loading dataset from val_dataset_LJ.json.\n",
      "262it [00:16, 15.57it/s]\n",
      "[NeMo I 2022-12-23 20:39:29 data:254] Loaded dataset with 262 files.\n",
      "[NeMo I 2022-12-23 20:39:29 data:256] Dataset contains 0.47 hours.\n",
      "[NeMo I 2022-12-23 20:39:29 data:358] Pruned 0 files. Final dataset contains 262 files\n",
      "[NeMo I 2022-12-23 20:39:29 data:360] Pruned 0.00 hours. Final dataset contains 0.47 hours.\n",
      "[NeMo W 2022-12-23 20:39:29 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      warnings.warn(_create_warning_msg(\n",
      "    \n",
      "[NeMo I 2022-12-23 20:39:29 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-23 20:39:29 features:275] STFT using exact pad\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-12-23 20:39:38 modelPT:616] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: False\n",
      "        lr: 0.001\n",
      "        maximize: False\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2022-12-23 20:39:38 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f552423c280>\" \n",
      "    will be used during training (effective maximum steps = 804) - \n",
      "    Parameters : \n",
      "    (min_lr: 1.0e-05\n",
      "    max_steps: 804\n",
      "    )\n",
      "\n",
      "  | Name                       | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0 | audio_to_melspec_precessor | FilterbankFeatures | 0     \n",
      "1 | text_embedding             | Embedding          | 58.4 K\n",
      "2 | encoder                    | Encoder            | 5.5 M \n",
      "3 | decoder                    | Decoder            | 18.3 M\n",
      "4 | postnet                    | Postnet            | 4.3 M \n",
      "5 | loss                       | Tacotron2Loss      | 0     \n",
      "------------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.703   Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 2/2 [00:02<00:00,  1.46s/it][NeMo W 2022-12-23 20:39:43 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/279 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  96%|████████▋| 268/279 [10:37<00:26,  2.38s/it, loss=1.53, v_num=1-03]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 20:50:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  96%|████████▋| 269/279 [10:39<00:23,  2.38s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 270/279 [10:40<00:21,  2.37s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 271/279 [10:42<00:18,  2.37s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▊| 272/279 [10:43<00:16,  2.37s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 273/279 [10:44<00:14,  2.36s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 274/279 [10:46<00:11,  2.36s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▊| 275/279 [10:47<00:09,  2.35s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 276/279 [10:48<00:07,  2.35s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 277/279 [10:50<00:04,  2.35s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|████████▉| 278/279 [10:51<00:02,  2.34s/it, loss=1.53, v_num=1-03]\u001b[A[NeMo W 2022-12-23 20:50:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|█████████| 279/279 [10:52<00:00,  2.34s/it, loss=1.53, v_num=1-03]\u001b[A\n",
      "Epoch 0: 100%|█████████| 279/279 [10:52<00:00,  2.34s/it, loss=1.53, v_num=1-03]\u001b[AEpoch 0, global step 268: 'val_loss' reached 6.31773 (best 6.31773), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_20-31-03/checkpoints/Tacotron2--val_loss=6.3177-epoch=0.ckpt' as top 3\n",
      "Epoch 1:  96%|████████▋| 268/279 [10:33<00:25,  2.36s/it, loss=1.25, v_num=1-03]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 21:01:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  96%|████████▋| 269/279 [10:35<00:23,  2.36s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 270/279 [10:36<00:21,  2.36s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 271/279 [10:38<00:18,  2.36s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▊| 272/279 [10:39<00:16,  2.35s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 273/279 [10:40<00:14,  2.35s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 274/279 [10:42<00:11,  2.34s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▊| 275/279 [10:43<00:09,  2.34s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 276/279 [10:44<00:07,  2.34s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 277/279 [10:46<00:04,  2.33s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|████████▉| 278/279 [10:47<00:02,  2.33s/it, loss=1.25, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:01:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|█████████| 279/279 [10:48<00:00,  2.33s/it, loss=1.25, v_num=1-03]\u001b[A\n",
      "Epoch 1: 100%|█████████| 279/279 [10:48<00:00,  2.33s/it, loss=1.25, v_num=1-03]\u001b[AEpoch 1, global step 536: 'val_loss' reached 6.26782 (best 6.26782), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_20-31-03/checkpoints/Tacotron2--val_loss=6.2678-epoch=1.ckpt' as top 3\n",
      "Epoch 2:  96%|████████▋| 268/279 [10:33<00:25,  2.36s/it, loss=1.13, v_num=1-03]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 21:12:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  96%|████████▋| 269/279 [10:35<00:23,  2.36s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 270/279 [10:36<00:21,  2.36s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 271/279 [10:38<00:18,  2.35s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▊| 272/279 [10:39<00:16,  2.35s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 273/279 [10:40<00:14,  2.35s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 274/279 [10:42<00:11,  2.34s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▊| 275/279 [10:43<00:09,  2.34s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 276/279 [10:44<00:07,  2.34s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 277/279 [10:46<00:04,  2.33s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|████████▉| 278/279 [10:47<00:02,  2.33s/it, loss=1.13, v_num=1-03]\u001b[A[NeMo W 2022-12-23 21:12:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|█████████| 279/279 [10:48<00:00,  2.33s/it, loss=1.13, v_num=1-03]\u001b[A\n",
      "Epoch 2: 100%|█████████| 279/279 [10:48<00:00,  2.33s/it, loss=1.13, v_num=1-03]\u001b[AEpoch 2, global step 804: 'val_loss' reached 11.91757 (best 6.26782), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_20-31-03/checkpoints/Tacotron2--val_loss=11.9176-epoch=2.ckpt' as top 3\n",
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "Epoch 2: 100%|█████████| 279/279 [10:49<00:00,  2.33s/it, loss=1.13, v_num=1-03]\n"
     ]
    }
   ],
   "source": [
    "!(python tacotron2.py \\\n",
    "  train_dataset=trn_dataset_LJ.json \\\n",
    "  validation_datasets=val_dataset_LJ.json \\\n",
    "  trainer.max_epochs=3 \\\n",
    "  trainer.accelerator=null \\\n",
    "  trainer.check_val_every_n_epoch=1 \\\n",
    " +trainer.gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ddd5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-23 21:12:57 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-23 21:13:12 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:12 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:12 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo W 2022-12-23 21:13:12 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-23 21:13:12 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:461: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-23 21:13:12 exp_manager:361] Experiments will be logged at /home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12\n",
      "[NeMo I 2022-12-23 21:13:12 exp_manager:766] TensorboardLogger has been set up\n",
      "[NeMo W 2022-12-23 21:13:12 exp_manager:1045] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-23 21:13:15 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-23 21:13:47 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:48 modules:95] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-23 21:13:49 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:50 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:50 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2022-12-23 21:13:50 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:50 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:50 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:50 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 21:13:50 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-12-23 21:13:51 data:217] Loading dataset from trn_dataset_LJ.json.\n",
      "12838it [07:55, 26.98it/s]\n",
      "[NeMo I 2022-12-23 21:21:47 data:254] Loaded dataset with 12838 files.\n",
      "[NeMo I 2022-12-23 21:21:47 data:256] Dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-23 21:21:47 data:358] Pruned 0 files. Final dataset contains 12838 files\n",
      "[NeMo I 2022-12-23 21:21:47 data:360] Pruned 0.00 hours. Final dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-23 21:21:47 data:217] Loading dataset from val_dataset_LJ.json.\n",
      "262it [00:17, 14.57it/s]\n",
      "[NeMo I 2022-12-23 21:22:05 data:254] Loaded dataset with 262 files.\n",
      "[NeMo I 2022-12-23 21:22:05 data:256] Dataset contains 0.47 hours.\n",
      "[NeMo I 2022-12-23 21:22:05 data:358] Pruned 0 files. Final dataset contains 262 files\n",
      "[NeMo I 2022-12-23 21:22:05 data:360] Pruned 0.00 hours. Final dataset contains 0.47 hours.\n",
      "[NeMo W 2022-12-23 21:22:05 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      warnings.warn(_create_warning_msg(\n",
      "    \n",
      "[NeMo I 2022-12-23 21:22:05 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-23 21:22:05 features:275] STFT using exact pad\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-12-23 21:22:08 modelPT:616] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: False\n",
      "        lr: 0.001\n",
      "        maximize: False\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2022-12-23 21:22:08 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fe2e4a4bee0>\" \n",
      "    will be used during training (effective maximum steps = 2680) - \n",
      "    Parameters : \n",
      "    (min_lr: 1.0e-05\n",
      "    max_steps: 2680\n",
      "    )\n",
      "\n",
      "  | Name                       | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0 | audio_to_melspec_precessor | FilterbankFeatures | 0     \n",
      "1 | text_embedding             | Embedding          | 58.4 K\n",
      "2 | encoder                    | Encoder            | 5.5 M \n",
      "3 | decoder                    | Decoder            | 18.3 M\n",
      "4 | postnet                    | Postnet            | 4.3 M \n",
      "5 | loss                       | Tacotron2Loss      | 0     \n",
      "------------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.703   Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s][NeMo W 2022-12-23 21:22:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "Sanity Checking DataLoader 0:  50%|███████▌       | 1/2 [00:04<00:04,  4.05s/it][NeMo W 2022-12-23 21:22:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 2/2 [00:05<00:00,  2.65s/it][NeMo W 2022-12-23 21:22:15 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/279 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  96%|████████▋| 268/279 [10:38<00:26,  2.38s/it, loss=1.56, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 21:32:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  96%|████████▋| 269/279 [10:40<00:23,  2.38s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:32:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 270/279 [10:41<00:21,  2.38s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:32:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 271/279 [10:43<00:18,  2.37s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▊| 272/279 [10:44<00:16,  2.37s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 273/279 [10:45<00:14,  2.37s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 274/279 [10:47<00:11,  2.36s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▊| 275/279 [10:48<00:09,  2.36s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 276/279 [10:49<00:07,  2.35s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 277/279 [10:51<00:04,  2.35s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|████████▉| 278/279 [10:52<00:02,  2.35s/it, loss=1.56, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:33:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|█████████| 279/279 [10:53<00:00,  2.34s/it, loss=1.56, v_num=3-12]\u001b[A\n",
      "Epoch 0: 100%|█████████| 279/279 [10:53<00:00,  2.34s/it, loss=1.56, v_num=3-12]Epoch 0, global step 268: 'val_loss' reached 5.73275 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=5.7327-epoch=0.ckpt' as top 3\n",
      "Epoch 1:  96%|████████▋| 268/279 [10:32<00:25,  2.36s/it, loss=1.24, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 21:43:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  96%|████████▋| 269/279 [10:35<00:23,  2.36s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 270/279 [10:36<00:21,  2.36s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 271/279 [10:37<00:18,  2.35s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▊| 272/279 [10:38<00:16,  2.35s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 273/279 [10:40<00:14,  2.35s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 274/279 [10:41<00:11,  2.34s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▊| 275/279 [10:42<00:09,  2.34s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 276/279 [10:44<00:07,  2.33s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 277/279 [10:45<00:04,  2.33s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|████████▉| 278/279 [10:46<00:02,  2.33s/it, loss=1.24, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:43:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|█████████| 279/279 [10:48<00:00,  2.32s/it, loss=1.24, v_num=3-12]\u001b[A\n",
      "Epoch 1: 100%|█████████| 279/279 [10:48<00:00,  2.32s/it, loss=1.24, v_num=3-12]Epoch 1, global step 536: 'val_loss' reached 11.82100 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=11.8210-epoch=1.ckpt' as top 3\n",
      "Epoch 2:  96%|████████▋| 268/279 [10:33<00:25,  2.36s/it, loss=1.06, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 21:54:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  96%|████████▋| 269/279 [10:35<00:23,  2.36s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 270/279 [10:36<00:21,  2.36s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 271/279 [10:38<00:18,  2.36s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▊| 272/279 [10:39<00:16,  2.35s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 273/279 [10:41<00:14,  2.35s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 274/279 [10:42<00:11,  2.34s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▊| 275/279 [10:43<00:09,  2.34s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 276/279 [10:45<00:07,  2.34s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 277/279 [10:46<00:04,  2.33s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|████████▉| 278/279 [10:47<00:02,  2.33s/it, loss=1.06, v_num=3-12]\u001b[A[NeMo W 2022-12-23 21:54:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|█████████| 279/279 [10:49<00:00,  2.33s/it, loss=1.06, v_num=3-12]\u001b[A\n",
      "Epoch 2: 100%|█████████| 279/279 [10:49<00:00,  2.33s/it, loss=1.06, v_num=3-12]Epoch 2, global step 804: 'val_loss' reached 11.62407 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=11.6241-epoch=2.ckpt' as top 3\n",
      "Epoch 3:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.905, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 22:05:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.905, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:05:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.905, v_num=3-12]\u001b[A\n",
      "Epoch 3: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.905, v_num=3-12]\u001b[AEpoch 3, global step 1072: 'val_loss' reached 8.99369 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=8.9937-epoch=3.ckpt' as top 3\n",
      "Epoch 4:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.818, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 22:16:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  96%|███████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 273/279 [10:40<00:14,  2.34s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|███████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.818, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:16:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.818, v_num=3-12]\u001b[A\n",
      "Epoch 4: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.818, v_num=3-12]Epoch 4, global step 1340: 'val_loss' reached 10.51817 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=10.5182-epoch=4.ckpt' as top 3\n",
      "Epoch 5:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.809, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 22:27:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  96%|███████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▋| 270/279 [10:35<00:21,  2.36s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|███████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.809, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:27:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.809, v_num=3-12]\u001b[A\n",
      "Epoch 5: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.809, v_num=3-12]Epoch 5, global step 1608: 'val_loss' reached 9.35958 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=9.3596-epoch=5.ckpt' as top 3\n",
      "Epoch 6:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.782, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 22:37:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:37:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:37:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:37:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:37:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:37:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:37:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:38:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:38:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:38:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.782, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:38:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.782, v_num=3-12]\u001b[A\n",
      "Epoch 6: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.782, v_num=3-12]Epoch 6, global step 1876: 'val_loss' reached 8.92595 (best 5.73275), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_21-13-12/checkpoints/Tacotron2--val_loss=8.9260-epoch=6.ckpt' as top 3\n",
      "Epoch 7:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.761, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 22:48:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  96%|███████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 273/279 [10:40<00:14,  2.34s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|███████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.761, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:48:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.761, v_num=3-12]\u001b[A\n",
      "Epoch 7: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.761, v_num=3-12]Epoch 7, global step 2144: 'val_loss' was not in top 3\n",
      "Epoch 8:  96%|███████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.749, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 22:59:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.749, v_num=3-12]\u001b[A[NeMo W 2022-12-23 22:59:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|████████| 279/279 [10:48<00:00,  2.33s/it, loss=0.749, v_num=3-12]\u001b[A\n",
      "Epoch 8: 100%|████████| 279/279 [10:48<00:00,  2.33s/it, loss=0.749, v_num=3-12]Epoch 8, global step 2412: 'val_loss' was not in top 3\n",
      "Epoch 9:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.753, v_num=3-12]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 23:10:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.753, v_num=3-12]\u001b[A[NeMo W 2022-12-23 23:10:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.753, v_num=3-12]\u001b[A\n",
      "Epoch 9: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.753, v_num=3-12]Epoch 9, global step 2680: 'val_loss' was not in top 3\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Epoch 9: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.753, v_num=3-12]\n"
     ]
    }
   ],
   "source": [
    "!(python tacotron2.py \\\n",
    "  train_dataset=trn_dataset_LJ.json \\\n",
    "  validation_datasets=val_dataset_LJ.json \\\n",
    "  trainer.max_epochs=10 \\\n",
    "  trainer.accelerator=null \\\n",
    "  trainer.check_val_every_n_epoch=1 \\\n",
    " +trainer.gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c4e977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-23 23:11:12 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-23 23:11:28 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:11:28 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:11:28 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo W 2022-12-23 23:11:28 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-23 23:11:28 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:461: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-23 23:11:29 exp_manager:361] Experiments will be logged at /home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29\n",
      "[NeMo I 2022-12-23 23:11:29 exp_manager:766] TensorboardLogger has been set up\n",
      "[NeMo W 2022-12-23 23:11:29 exp_manager:1045] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-23 23:11:31 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-23 23:12:04 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:05 modules:95] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-23 23:12:05 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:07 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:07 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2022-12-23 23:12:08 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:08 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:08 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:08 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-23 23:12:08 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-12-23 23:12:08 data:217] Loading dataset from trn_dataset_LJ.json.\n",
      "12838it [07:46, 27.52it/s]\n",
      "[NeMo I 2022-12-23 23:19:54 data:254] Loaded dataset with 12838 files.\n",
      "[NeMo I 2022-12-23 23:19:54 data:256] Dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-23 23:19:54 data:358] Pruned 0 files. Final dataset contains 12838 files\n",
      "[NeMo I 2022-12-23 23:19:54 data:360] Pruned 0.00 hours. Final dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-23 23:19:55 data:217] Loading dataset from val_dataset_LJ.json.\n",
      "262it [00:17, 14.97it/s]\n",
      "[NeMo I 2022-12-23 23:20:12 data:254] Loaded dataset with 262 files.\n",
      "[NeMo I 2022-12-23 23:20:12 data:256] Dataset contains 0.47 hours.\n",
      "[NeMo I 2022-12-23 23:20:12 data:358] Pruned 0 files. Final dataset contains 262 files\n",
      "[NeMo I 2022-12-23 23:20:12 data:360] Pruned 0.00 hours. Final dataset contains 0.47 hours.\n",
      "[NeMo W 2022-12-23 23:20:12 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      warnings.warn(_create_warning_msg(\n",
      "    \n",
      "[NeMo I 2022-12-23 23:20:12 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-23 23:20:12 features:275] STFT using exact pad\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-12-23 23:20:15 modelPT:616] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: False\n",
      "        lr: 0.001\n",
      "        maximize: False\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2022-12-23 23:20:15 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fb851341fd0>\" \n",
      "    will be used during training (effective maximum steps = 8040) - \n",
      "    Parameters : \n",
      "    (min_lr: 1.0e-05\n",
      "    max_steps: 8040\n",
      "    )\n",
      "\n",
      "  | Name                       | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0 | audio_to_melspec_precessor | FilterbankFeatures | 0     \n",
      "1 | text_embedding             | Embedding          | 58.4 K\n",
      "2 | encoder                    | Encoder            | 5.5 M \n",
      "3 | decoder                    | Decoder            | 18.3 M\n",
      "4 | postnet                    | Postnet            | 4.3 M \n",
      "5 | loss                       | Tacotron2Loss      | 0     \n",
      "------------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.703   Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 2/2 [00:03<00:00,  1.56s/it][NeMo W 2022-12-23 23:20:21 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/279 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  96%|████████▋| 268/279 [10:41<00:26,  2.40s/it, loss=1.54, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 23:31:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  96%|████████▋| 269/279 [10:44<00:23,  2.39s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 270/279 [10:45<00:21,  2.39s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 271/279 [10:46<00:19,  2.39s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▊| 272/279 [10:48<00:16,  2.38s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 273/279 [10:49<00:14,  2.38s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 274/279 [10:50<00:11,  2.38s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▊| 275/279 [10:52<00:09,  2.37s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 276/279 [10:53<00:07,  2.37s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 277/279 [10:55<00:04,  2.36s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|████████▉| 278/279 [10:56<00:02,  2.36s/it, loss=1.54, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:31:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|█████████| 279/279 [10:57<00:00,  2.36s/it, loss=1.54, v_num=1-29]\u001b[A\n",
      "Epoch 0: 100%|█████████| 279/279 [10:57<00:00,  2.36s/it, loss=1.54, v_num=1-29]Epoch 0, global step 268: 'val_loss' reached 6.51834 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=6.5183-epoch=0.ckpt' as top 3\n",
      "Epoch 1:  96%|████████▋| 268/279 [10:39<00:26,  2.39s/it, loss=1.18, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 23:42:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  96%|████████▋| 269/279 [10:41<00:23,  2.39s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 270/279 [10:42<00:21,  2.38s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 271/279 [10:44<00:19,  2.38s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▊| 272/279 [10:45<00:16,  2.37s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 273/279 [10:47<00:14,  2.37s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 274/279 [10:48<00:11,  2.37s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▊| 275/279 [10:49<00:09,  2.36s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 276/279 [10:51<00:07,  2.36s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 277/279 [10:52<00:04,  2.36s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|████████▉| 278/279 [10:53<00:02,  2.35s/it, loss=1.18, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:42:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|█████████| 279/279 [10:55<00:00,  2.35s/it, loss=1.18, v_num=1-29]\u001b[A\n",
      "Epoch 1: 100%|█████████| 279/279 [10:55<00:00,  2.35s/it, loss=1.18, v_num=1-29]Epoch 1, global step 536: 'val_loss' reached 13.71329 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=13.7133-epoch=1.ckpt' as top 3\n",
      "Epoch 2:  96%|████████▋| 268/279 [10:40<00:26,  2.39s/it, loss=0.98, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-23 23:52:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  96%|████████▋| 269/279 [10:43<00:23,  2.39s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 270/279 [10:44<00:21,  2.39s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 271/279 [10:45<00:19,  2.38s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▊| 272/279 [10:47<00:16,  2.38s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 273/279 [10:48<00:14,  2.38s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 274/279 [10:50<00:11,  2.37s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▊| 275/279 [10:51<00:09,  2.37s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 276/279 [10:52<00:07,  2.37s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 277/279 [10:54<00:04,  2.36s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|████████▉| 278/279 [10:55<00:02,  2.36s/it, loss=0.98, v_num=1-29]\u001b[A[NeMo W 2022-12-23 23:53:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|█████████| 279/279 [10:56<00:00,  2.35s/it, loss=0.98, v_num=1-29]\u001b[A\n",
      "Epoch 2: 100%|█████████| 279/279 [10:56<00:00,  2.35s/it, loss=0.98, v_num=1-29]Epoch 2, global step 804: 'val_loss' reached 12.18712 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=12.1871-epoch=2.ckpt' as top 3\n",
      "Epoch 3:  96%|███████▋| 268/279 [10:37<00:26,  2.38s/it, loss=0.878, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 00:03:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  96%|███████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:03:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▋| 270/279 [10:41<00:21,  2.38s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:03:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 271/279 [10:42<00:18,  2.37s/it, loss=0.878, v_num=1-29][NeMo W 2022-12-24 00:03:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 272/279 [10:44<00:16,  2.37s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:03:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 273/279 [10:45<00:14,  2.37s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:04:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 274/279 [10:47<00:11,  2.36s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:04:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 275/279 [10:48<00:09,  2.36s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:04:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 276/279 [10:49<00:07,  2.35s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:04:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 277/279 [10:51<00:04,  2.35s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:04:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|███████▉| 278/279 [10:52<00:02,  2.35s/it, loss=0.878, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:04:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|████████| 279/279 [10:53<00:00,  2.34s/it, loss=0.878, v_num=1-29]\u001b[A\n",
      "Epoch 3: 100%|████████| 279/279 [10:53<00:00,  2.34s/it, loss=0.878, v_num=1-29]Epoch 3, global step 1072: 'val_loss' reached 11.38401 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=11.3840-epoch=3.ckpt' as top 3\n",
      "Epoch 4:  96%|███████▋| 268/279 [10:39<00:26,  2.39s/it, loss=0.823, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 00:14:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  96%|███████▋| 269/279 [10:41<00:23,  2.39s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▋| 270/279 [10:43<00:21,  2.38s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 271/279 [10:44<00:19,  2.38s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 272/279 [10:45<00:16,  2.37s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 273/279 [10:47<00:14,  2.37s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 274/279 [10:48<00:11,  2.37s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 275/279 [10:49<00:09,  2.36s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:14:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 276/279 [10:51<00:07,  2.36s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:15:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 277/279 [10:52<00:04,  2.36s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:15:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|███████▉| 278/279 [10:53<00:02,  2.35s/it, loss=0.823, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:15:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|████████| 279/279 [10:55<00:00,  2.35s/it, loss=0.823, v_num=1-29]\u001b[A\n",
      "Epoch 4: 100%|████████| 279/279 [10:55<00:00,  2.35s/it, loss=0.823, v_num=1-29]Epoch 4, global step 1340: 'val_loss' reached 11.56176 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=11.5618-epoch=4.ckpt' as top 3\n",
      "Epoch 5:  96%|███████▋| 268/279 [10:38<00:26,  2.38s/it, loss=0.788, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 00:25:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  96%|███████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▋| 270/279 [10:42<00:21,  2.38s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 271/279 [10:44<00:19,  2.38s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 272/279 [10:45<00:16,  2.37s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 273/279 [10:46<00:14,  2.37s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 274/279 [10:48<00:11,  2.37s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 275/279 [10:49<00:09,  2.36s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 276/279 [10:50<00:07,  2.36s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 277/279 [10:52<00:04,  2.35s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|███████▉| 278/279 [10:53<00:02,  2.35s/it, loss=0.788, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:25:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|████████| 279/279 [10:54<00:00,  2.35s/it, loss=0.788, v_num=1-29]\u001b[A\n",
      "Epoch 5: 100%|████████| 279/279 [10:54<00:00,  2.35s/it, loss=0.788, v_num=1-29]Epoch 5, global step 1608: 'val_loss' reached 9.29788 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=9.2979-epoch=5.ckpt' as top 3\n",
      "Epoch 6:  96%|███████▋| 268/279 [10:36<00:26,  2.38s/it, loss=0.757, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 00:36:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  96%|███████▋| 269/279 [10:39<00:23,  2.38s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▋| 270/279 [10:40<00:21,  2.37s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 271/279 [10:41<00:18,  2.37s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 272/279 [10:43<00:16,  2.36s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 273/279 [10:44<00:14,  2.36s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 274/279 [10:45<00:11,  2.36s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 275/279 [10:47<00:09,  2.35s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 276/279 [10:48<00:07,  2.35s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 277/279 [10:49<00:04,  2.35s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|███████▉| 278/279 [10:51<00:02,  2.34s/it, loss=0.757, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:36:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|████████| 279/279 [10:52<00:00,  2.34s/it, loss=0.757, v_num=1-29]\u001b[A\n",
      "Epoch 6: 100%|████████| 279/279 [10:52<00:00,  2.34s/it, loss=0.757, v_num=1-29]Epoch 6, global step 1876: 'val_loss' was not in top 3\n",
      "Epoch 7:  96%|███████▋| 268/279 [10:38<00:26,  2.38s/it, loss=0.722, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 00:47:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  96%|███████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▋| 270/279 [10:41<00:21,  2.38s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 271/279 [10:43<00:18,  2.37s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 272/279 [10:44<00:16,  2.37s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 273/279 [10:45<00:14,  2.37s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 274/279 [10:47<00:11,  2.36s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 275/279 [10:48<00:09,  2.36s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 276/279 [10:50<00:07,  2.36s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 277/279 [10:51<00:04,  2.35s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|███████▉| 278/279 [10:52<00:02,  2.35s/it, loss=0.722, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:47:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|████████| 279/279 [10:54<00:00,  2.34s/it, loss=0.722, v_num=1-29]\u001b[A\n",
      "Epoch 7: 100%|████████| 279/279 [10:54<00:00,  2.34s/it, loss=0.722, v_num=1-29]Epoch 7, global step 2144: 'val_loss' reached 8.80325 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=8.8033-epoch=7.ckpt' as top 3\n",
      "Epoch 8:  96%|███████▋| 268/279 [10:37<00:26,  2.38s/it, loss=0.708, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 00:58:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  96%|███████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▋| 270/279 [10:41<00:21,  2.38s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 271/279 [10:43<00:18,  2.37s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 272/279 [10:44<00:16,  2.37s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 273/279 [10:45<00:14,  2.37s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 274/279 [10:47<00:11,  2.36s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 275/279 [10:48<00:09,  2.36s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 276/279 [10:49<00:07,  2.35s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 277/279 [10:51<00:04,  2.35s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|███████▉| 278/279 [10:52<00:02,  2.35s/it, loss=0.708, v_num=1-29]\u001b[A[NeMo W 2022-12-24 00:58:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|████████| 279/279 [10:53<00:00,  2.34s/it, loss=0.708, v_num=1-29]\u001b[A\n",
      "Epoch 8: 100%|████████| 279/279 [10:53<00:00,  2.34s/it, loss=0.708, v_num=1-29]Epoch 8, global step 2412: 'val_loss' was not in top 3\n",
      "Epoch 9:  96%|███████▋| 268/279 [10:37<00:26,  2.38s/it, loss=0.699, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 01:09:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  96%|███████▋| 269/279 [10:39<00:23,  2.38s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▋| 270/279 [10:40<00:21,  2.37s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 271/279 [10:42<00:18,  2.37s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 272/279 [10:43<00:16,  2.37s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 273/279 [10:44<00:14,  2.36s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 274/279 [10:46<00:11,  2.36s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 275/279 [10:47<00:09,  2.35s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 276/279 [10:48<00:07,  2.35s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 277/279 [10:50<00:04,  2.35s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|███████▉| 278/279 [10:51<00:02,  2.34s/it, loss=0.699, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:09:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|████████| 279/279 [10:52<00:00,  2.34s/it, loss=0.699, v_num=1-29]\u001b[A\n",
      "Epoch 9: 100%|████████| 279/279 [10:52<00:00,  2.34s/it, loss=0.699, v_num=1-29]Epoch 9, global step 2680: 'val_loss' was not in top 3\n",
      "Epoch 10:  96%|██████▋| 268/279 [10:38<00:26,  2.38s/it, loss=0.691, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 01:20:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  96%|██████▋| 269/279 [10:41<00:23,  2.38s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 270/279 [10:42<00:21,  2.38s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 271/279 [10:43<00:19,  2.38s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 272/279 [10:45<00:16,  2.37s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  98%|██████▊| 273/279 [10:46<00:14,  2.37s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  98%|██████▊| 274/279 [10:48<00:11,  2.37s/it, loss=0.691, v_num=1-29][NeMo W 2022-12-24 01:20:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 275/279 [10:49<00:09,  2.36s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 276/279 [10:50<00:07,  2.36s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 277/279 [10:52<00:04,  2.35s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10: 100%|██████▉| 278/279 [10:53<00:02,  2.35s/it, loss=0.691, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:20:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10: 100%|███████| 279/279 [10:54<00:00,  2.35s/it, loss=0.691, v_num=1-29]\u001b[A\n",
      "Epoch 10: 100%|███████| 279/279 [10:54<00:00,  2.35s/it, loss=0.691, v_num=1-29]Epoch 10, global step 2948: 'val_loss' was not in top 3\n",
      "Epoch 11:  96%|██████▋| 268/279 [10:37<00:26,  2.38s/it, loss=0.655, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 01:31:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  96%|██████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 270/279 [10:41<00:21,  2.38s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 271/279 [10:42<00:18,  2.37s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 272/279 [10:44<00:16,  2.37s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  98%|██████▊| 273/279 [10:45<00:14,  2.36s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  98%|██████▊| 274/279 [10:46<00:11,  2.36s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 275/279 [10:48<00:09,  2.36s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 276/279 [10:49<00:07,  2.35s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 277/279 [10:51<00:04,  2.35s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11: 100%|██████▉| 278/279 [10:52<00:02,  2.35s/it, loss=0.655, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:31:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11: 100%|███████| 279/279 [10:53<00:00,  2.34s/it, loss=0.655, v_num=1-29]\u001b[A\n",
      "Epoch 11: 100%|███████| 279/279 [10:53<00:00,  2.34s/it, loss=0.655, v_num=1-29]Epoch 11, global step 3216: 'val_loss' was not in top 3\n",
      "Epoch 12:  96%|██████▋| 268/279 [10:38<00:26,  2.38s/it, loss=0.659, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 01:42:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  96%|██████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 270/279 [10:42<00:21,  2.38s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 271/279 [10:43<00:18,  2.37s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 272/279 [10:44<00:16,  2.37s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  98%|██████▊| 273/279 [10:46<00:14,  2.37s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  98%|██████▊| 274/279 [10:47<00:11,  2.36s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 275/279 [10:48<00:09,  2.36s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 276/279 [10:50<00:07,  2.36s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 277/279 [10:51<00:04,  2.35s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12: 100%|██████▉| 278/279 [10:52<00:02,  2.35s/it, loss=0.659, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:42:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12: 100%|███████| 279/279 [10:54<00:00,  2.35s/it, loss=0.659, v_num=1-29]\u001b[A\n",
      "Epoch 12: 100%|███████| 279/279 [10:54<00:00,  2.35s/it, loss=0.659, v_num=1-29]Epoch 12, global step 3484: 'val_loss' was not in top 3\n",
      "Epoch 13:  96%|██████▋| 268/279 [10:37<00:26,  2.38s/it, loss=0.638, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 01:52:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  96%|██████▋| 269/279 [10:39<00:23,  2.38s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|██████▊| 270/279 [10:41<00:21,  2.37s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|██████▊| 271/279 [10:42<00:18,  2.37s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|██████▊| 272/279 [10:43<00:16,  2.37s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  98%|██████▊| 273/279 [10:45<00:14,  2.36s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  98%|██████▊| 274/279 [10:46<00:11,  2.36s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|██████▉| 275/279 [10:47<00:09,  2.36s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|██████▉| 276/279 [10:49<00:07,  2.35s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|██████▉| 277/279 [10:50<00:04,  2.35s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13: 100%|██████▉| 278/279 [10:51<00:02,  2.35s/it, loss=0.638, v_num=1-29]\u001b[A[NeMo W 2022-12-24 01:53:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13: 100%|███████| 279/279 [10:53<00:00,  2.34s/it, loss=0.638, v_num=1-29]\u001b[A\n",
      "Epoch 13: 100%|███████| 279/279 [10:53<00:00,  2.34s/it, loss=0.638, v_num=1-29]Epoch 13, global step 3752: 'val_loss' reached 8.35692 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=8.3569-epoch=13.ckpt' as top 3\n",
      "Epoch 14:  96%|██████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.642, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 02:03:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:03:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 270/279 [10:39<00:21,  2.37s/it, loss=0.642, v_num=1-29][NeMo W 2022-12-24 02:03:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:03:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 272/279 [10:42<00:16,  2.36s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:03:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  98%|██████▊| 273/279 [10:43<00:14,  2.36s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:03:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:04:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 275/279 [10:46<00:09,  2.35s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:04:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 276/279 [10:47<00:07,  2.35s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:04:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:04:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14: 100%|██████▉| 278/279 [10:50<00:02,  2.34s/it, loss=0.642, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:04:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14: 100%|███████| 279/279 [10:51<00:00,  2.34s/it, loss=0.642, v_num=1-29]\u001b[A\n",
      "Epoch 14: 100%|███████| 279/279 [10:51<00:00,  2.34s/it, loss=0.642, v_num=1-29]Epoch 14, global step 4020: 'val_loss' was not in top 3\n",
      "Epoch 15:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.627, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 02:14:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.627, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:14:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.627, v_num=1-29]\u001b[A\n",
      "Epoch 15: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.627, v_num=1-29]Epoch 15, global step 4288: 'val_loss' was not in top 3\n",
      "Epoch 16:  96%|██████▋| 268/279 [10:33<00:26,  2.37s/it, loss=0.621, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 02:25:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:25:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.621, v_num=1-29]\u001b[A\n",
      "Epoch 16: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.621, v_num=1-29]Epoch 16, global step 4556: 'val_loss' was not in top 3\n",
      "Epoch 17:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.613, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 02:36:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.613, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:36:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.613, v_num=1-29]\u001b[A\n",
      "Epoch 17: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.613, v_num=1-29]Epoch 17, global step 4824: 'val_loss' was not in top 3\n",
      "Epoch 18:  96%|██████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.621, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 02:47:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 270/279 [10:39<00:21,  2.37s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  98%|██████▊| 273/279 [10:43<00:14,  2.36s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 276/279 [10:47<00:07,  2.34s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18: 100%|██████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.621, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:47:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.621, v_num=1-29]\u001b[A\n",
      "Epoch 18: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.621, v_num=1-29]Epoch 18, global step 5092: 'val_loss' was not in top 3\n",
      "Epoch 19:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.598, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 02:58:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.598, v_num=1-29]\u001b[A[NeMo W 2022-12-24 02:58:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.598, v_num=1-29]\u001b[A\n",
      "Epoch 19: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.598, v_num=1-29]Epoch 19, global step 5360: 'val_loss' reached 8.00396 (best 6.51834), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-23_23-11-29/checkpoints/Tacotron2--val_loss=8.0040-epoch=19.ckpt' as top 3\n",
      "Epoch 20:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.607, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 03:08:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:08:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 270/279 [10:38<00:21,  2.36s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:08:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:08:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:08:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  98%|██████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:09:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:09:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 275/279 [10:44<00:09,  2.35s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:09:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:09:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:09:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.607, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:09:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.607, v_num=1-29]\u001b[A\n",
      "Epoch 20: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.607, v_num=1-29]Epoch 20, global step 5628: 'val_loss' was not in top 3\n",
      "Epoch 21:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.606, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 03:19:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 271/279 [10:38<00:18,  2.35s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.606, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:19:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.606, v_num=1-29]\u001b[A\n",
      "Epoch 21: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.606, v_num=1-29]Epoch 21, global step 5896: 'val_loss' was not in top 3\n",
      "Epoch 22:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.581, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 03:30:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:30:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.581, v_num=1-29]\u001b[A\n",
      "Epoch 22: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.581, v_num=1-29]Epoch 22, global step 6164: 'val_loss' was not in top 3\n",
      "Epoch 23:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.594, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 03:41:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.594, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:41:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.594, v_num=1-29]\u001b[A\n",
      "Epoch 23: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.594, v_num=1-29]Epoch 23, global step 6432: 'val_loss' was not in top 3\n",
      "Epoch 24:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.589, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 03:52:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 270/279 [10:35<00:21,  2.36s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.589, v_num=1-29]\u001b[A[NeMo W 2022-12-24 03:52:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.589, v_num=1-29]\u001b[A\n",
      "Epoch 24: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.589, v_num=1-29]Epoch 24, global step 6700: 'val_loss' was not in top 3\n",
      "Epoch 25:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.585, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 04:02:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.585, v_num=1-29][NeMo W 2022-12-24 04:03:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 275/279 [10:42<00:09,  2.33s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25: 100%|██████▉| 278/279 [10:46<00:02,  2.32s/it, loss=0.585, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:03:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.585, v_num=1-29]\u001b[A\n",
      "Epoch 25: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.585, v_num=1-29]Epoch 25, global step 6968: 'val_loss' was not in top 3\n",
      "Epoch 26:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.581, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 04:13:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:13:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:14:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.581, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:14:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.581, v_num=1-29]\u001b[A\n",
      "Epoch 26: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.581, v_num=1-29]Epoch 26, global step 7236: 'val_loss' was not in top 3\n",
      "Epoch 27:  96%|███████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.57, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 04:24:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|███████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  98%|███████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|███████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|███████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:24:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.57, v_num=1-29]\u001b[A\n",
      "Epoch 27: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.57, v_num=1-29]Epoch 27, global step 7504: 'val_loss' was not in top 3\n",
      "Epoch 28:  96%|███████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.57, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 04:35:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  96%|███████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|███████▋| 270/279 [10:37<00:21,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|███████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|███████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  98%|███████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  98%|███████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|███████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|███████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|███████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28: 100%|███████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:35:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.57, v_num=1-29]\u001b[A\n",
      "Epoch 28: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.57, v_num=1-29]\u001b[AEpoch 28, global step 7772: 'val_loss' was not in top 3\n",
      "Epoch 29:  96%|███████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.57, v_num=1-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 04:46:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  96%|███████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|███████▋| 270/279 [10:38<00:21,  2.37s/it, loss=0.57, v_num=1-29][NeMo W 2022-12-24 04:46:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|███████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|███████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  98%|███████▊| 273/279 [10:42<00:14,  2.36s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  98%|███████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|███████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|███████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|███████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29: 100%|███████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.57, v_num=1-29]\u001b[A[NeMo W 2022-12-24 04:46:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29: 100%|████████| 279/279 [10:51<00:00,  2.33s/it, loss=0.57, v_num=1-29]\u001b[A\n",
      "Epoch 29: 100%|████████| 279/279 [10:51<00:00,  2.33s/it, loss=0.57, v_num=1-29]Epoch 29, global step 8040: 'val_loss' was not in top 3\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "Epoch 29: 100%|████████| 279/279 [10:51<00:00,  2.34s/it, loss=0.57, v_num=1-29]\n"
     ]
    }
   ],
   "source": [
    "!(python tacotron2.py \\\n",
    "  train_dataset=trn_dataset_LJ.json \\\n",
    "  validation_datasets=val_dataset_LJ.json \\\n",
    "  trainer.max_epochs=30 \\\n",
    "  trainer.accelerator=null \\\n",
    "  trainer.check_val_every_n_epoch=1 \\\n",
    " +trainer.gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e83b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-24 04:47:13 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-24 04:47:29 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:47:29 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:47:29 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo W 2022-12-24 04:47:29 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-24 04:47:29 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:461: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-24 04:47:29 exp_manager:361] Experiments will be logged at /home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29\n",
      "[NeMo I 2022-12-24 04:47:29 exp_manager:766] TensorboardLogger has been set up\n",
      "[NeMo W 2022-12-24 04:47:29 exp_manager:1045] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-24 04:47:32 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-24 04:48:03 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:04 modules:95] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-24 04:48:05 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:07 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:07 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2022-12-24 04:48:07 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:07 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:07 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:07 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 04:48:07 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-12-24 04:48:07 data:217] Loading dataset from trn_dataset_LJ.json.\n",
      "12838it [07:40, 27.89it/s]\n",
      "[NeMo I 2022-12-24 04:55:48 data:254] Loaded dataset with 12838 files.\n",
      "[NeMo I 2022-12-24 04:55:48 data:256] Dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-24 04:55:48 data:358] Pruned 0 files. Final dataset contains 12838 files\n",
      "[NeMo I 2022-12-24 04:55:48 data:360] Pruned 0.00 hours. Final dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-24 04:55:48 data:217] Loading dataset from val_dataset_LJ.json.\n",
      "262it [00:16, 15.83it/s]\n",
      "[NeMo I 2022-12-24 04:56:04 data:254] Loaded dataset with 262 files.\n",
      "[NeMo I 2022-12-24 04:56:04 data:256] Dataset contains 0.47 hours.\n",
      "[NeMo I 2022-12-24 04:56:04 data:358] Pruned 0 files. Final dataset contains 262 files\n",
      "[NeMo I 2022-12-24 04:56:04 data:360] Pruned 0.00 hours. Final dataset contains 0.47 hours.\n",
      "[NeMo W 2022-12-24 04:56:04 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      warnings.warn(_create_warning_msg(\n",
      "    \n",
      "[NeMo I 2022-12-24 04:56:04 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-24 04:56:04 features:275] STFT using exact pad\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-12-24 04:56:07 modelPT:616] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: False\n",
      "        lr: 0.001\n",
      "        maximize: False\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2022-12-24 04:56:07 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f52b8193250>\" \n",
      "    will be used during training (effective maximum steps = 26800) - \n",
      "    Parameters : \n",
      "    (min_lr: 1.0e-05\n",
      "    max_steps: 26800\n",
      "    )\n",
      "\n",
      "  | Name                       | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0 | audio_to_melspec_precessor | FilterbankFeatures | 0     \n",
      "1 | text_embedding             | Embedding          | 58.4 K\n",
      "2 | encoder                    | Encoder            | 5.5 M \n",
      "3 | decoder                    | Decoder            | 18.3 M\n",
      "4 | postnet                    | Postnet            | 4.3 M \n",
      "5 | loss                       | Tacotron2Loss      | 0     \n",
      "------------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.703   Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 2/2 [00:03<00:00,  1.64s/it][NeMo W 2022-12-24 04:56:13 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/279 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  96%|████████▋| 268/279 [10:40<00:26,  2.39s/it, loss=1.73, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 05:06:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  96%|████████▋| 269/279 [10:43<00:23,  2.39s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:06:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 270/279 [10:44<00:21,  2.39s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:06:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 271/279 [10:45<00:19,  2.38s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▊| 272/279 [10:47<00:16,  2.38s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 273/279 [10:48<00:14,  2.38s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 274/279 [10:49<00:11,  2.37s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▊| 275/279 [10:51<00:09,  2.37s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 276/279 [10:52<00:07,  2.36s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 277/279 [10:53<00:04,  2.36s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|████████▉| 278/279 [10:55<00:02,  2.36s/it, loss=1.73, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:07:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|█████████| 279/279 [10:56<00:00,  2.35s/it, loss=1.73, v_num=7-29]\u001b[A\n",
      "Epoch 0: 100%|█████████| 279/279 [10:56<00:00,  2.35s/it, loss=1.73, v_num=7-29]Epoch 0, global step 268: 'val_loss' reached 5.45253 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=5.4525-epoch=0.ckpt' as top 3\n",
      "Epoch 1:  96%|████████▋| 268/279 [10:34<00:26,  2.37s/it, loss=1.25, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 05:17:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  96%|████████▋| 269/279 [10:36<00:23,  2.37s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 270/279 [10:37<00:21,  2.36s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 271/279 [10:39<00:18,  2.36s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▊| 272/279 [10:40<00:16,  2.35s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 273/279 [10:41<00:14,  2.35s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 274/279 [10:43<00:11,  2.35s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▊| 275/279 [10:44<00:09,  2.34s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 276/279 [10:45<00:07,  2.34s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 277/279 [10:47<00:04,  2.34s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:17:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|████████▉| 278/279 [10:48<00:02,  2.33s/it, loss=1.25, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:18:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|█████████| 279/279 [10:49<00:00,  2.33s/it, loss=1.25, v_num=7-29]\u001b[A\n",
      "Epoch 1: 100%|█████████| 279/279 [10:49<00:00,  2.33s/it, loss=1.25, v_num=7-29]Epoch 1, global step 536: 'val_loss' reached 8.16828 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=8.1683-epoch=1.ckpt' as top 3\n",
      "Epoch 2:  96%|████████▋| 268/279 [10:34<00:26,  2.37s/it, loss=1.04, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 05:28:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  96%|████████▋| 269/279 [10:37<00:23,  2.37s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 270/279 [10:38<00:21,  2.36s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▋| 271/279 [10:39<00:18,  2.36s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|████████▊| 272/279 [10:41<00:16,  2.36s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 273/279 [10:42<00:14,  2.35s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|████████▊| 274/279 [10:43<00:11,  2.35s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▊| 275/279 [10:45<00:09,  2.35s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 276/279 [10:46<00:07,  2.34s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|████████▉| 277/279 [10:47<00:04,  2.34s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|████████▉| 278/279 [10:49<00:02,  2.34s/it, loss=1.04, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:28:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|█████████| 279/279 [10:50<00:00,  2.33s/it, loss=1.04, v_num=7-29]\u001b[A\n",
      "Epoch 2: 100%|█████████| 279/279 [10:50<00:00,  2.33s/it, loss=1.04, v_num=7-29]Epoch 2, global step 804: 'val_loss' reached 11.68499 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=11.6850-epoch=2.ckpt' as top 3\n",
      "Epoch 3:  96%|███████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.907, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 05:39:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▋| 270/279 [10:37<00:21,  2.36s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.907, v_num=7-29][NeMo W 2022-12-24 05:39:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.907, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:39:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.907, v_num=7-29]\u001b[A\n",
      "Epoch 3: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.907, v_num=7-29]\u001b[AEpoch 3, global step 1072: 'val_loss' reached 8.39893 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=8.3989-epoch=3.ckpt' as top 3\n",
      "Epoch 4:  96%|███████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.826, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 05:50:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  96%|███████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▋| 270/279 [10:38<00:21,  2.36s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|███████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.826, v_num=7-29]\u001b[A[NeMo W 2022-12-24 05:50:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.826, v_num=7-29]\u001b[A\n",
      "Epoch 4: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.826, v_num=7-29]Epoch 4, global step 1340: 'val_loss' was not in top 3\n",
      "Epoch 5:  96%|███████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.771, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 06:01:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  96%|███████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▋| 270/279 [10:38<00:21,  2.37s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 273/279 [10:42<00:14,  2.36s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|███████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.771, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:01:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.771, v_num=7-29]\u001b[A\n",
      "Epoch 5: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.771, v_num=7-29]Epoch 5, global step 1608: 'val_loss' was not in top 3\n",
      "Epoch 6:  96%|███████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.744, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 06:12:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  96%|███████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▋| 270/279 [10:38<00:21,  2.37s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 273/279 [10:42<00:14,  2.36s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 276/279 [10:47<00:07,  2.34s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|███████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.744, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:12:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|████████| 279/279 [10:51<00:00,  2.33s/it, loss=0.744, v_num=7-29]\u001b[A\n",
      "Epoch 6: 100%|████████| 279/279 [10:51<00:00,  2.33s/it, loss=0.744, v_num=7-29]Epoch 6, global step 1876: 'val_loss' reached 6.90387 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=6.9039-epoch=6.ckpt' as top 3\n",
      "Epoch 7:  96%|███████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.725, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 06:22:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  96%|███████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:22:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▋| 270/279 [10:38<00:21,  2.37s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:22:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:22:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:22:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:23:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:23:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:23:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:23:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:23:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|███████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.725, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:23:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.725, v_num=7-29]\u001b[A\n",
      "Epoch 7: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.725, v_num=7-29]Epoch 7, global step 2144: 'val_loss' was not in top 3\n",
      "Epoch 8:  96%|███████▋| 268/279 [10:37<00:26,  2.38s/it, loss=0.696, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 06:33:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  96%|███████▋| 269/279 [10:40<00:23,  2.38s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▋| 270/279 [10:41<00:21,  2.38s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 271/279 [10:42<00:18,  2.37s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 272/279 [10:44<00:16,  2.37s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 273/279 [10:45<00:14,  2.36s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 274/279 [10:46<00:11,  2.36s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 275/279 [10:48<00:09,  2.36s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 276/279 [10:49<00:07,  2.35s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:33:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 277/279 [10:50<00:04,  2.35s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:34:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|███████▉| 278/279 [10:52<00:02,  2.35s/it, loss=0.696, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:34:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|████████| 279/279 [10:53<00:00,  2.34s/it, loss=0.696, v_num=7-29]\u001b[A\n",
      "Epoch 8: 100%|████████| 279/279 [10:53<00:00,  2.34s/it, loss=0.696, v_num=7-29]Epoch 8, global step 2412: 'val_loss' was not in top 3\n",
      "Epoch 9:  96%|███████▋| 268/279 [10:36<00:26,  2.38s/it, loss=0.685, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 06:44:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  96%|███████▋| 269/279 [10:38<00:23,  2.37s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▋| 270/279 [10:40<00:21,  2.37s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 271/279 [10:41<00:18,  2.37s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 272/279 [10:42<00:16,  2.36s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 273/279 [10:44<00:14,  2.36s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 274/279 [10:45<00:11,  2.36s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 275/279 [10:46<00:09,  2.35s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 276/279 [10:48<00:07,  2.35s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 277/279 [10:49<00:04,  2.34s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|███████▉| 278/279 [10:50<00:02,  2.34s/it, loss=0.685, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:44:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|████████| 279/279 [10:52<00:00,  2.34s/it, loss=0.685, v_num=7-29]\u001b[A\n",
      "Epoch 9: 100%|████████| 279/279 [10:52<00:00,  2.34s/it, loss=0.685, v_num=7-29]Epoch 9, global step 2680: 'val_loss' was not in top 3\n",
      "Epoch 10:  96%|██████▋| 268/279 [10:36<00:26,  2.37s/it, loss=0.662, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 06:55:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  96%|██████▋| 269/279 [10:38<00:23,  2.37s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 270/279 [10:40<00:21,  2.37s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 271/279 [10:41<00:18,  2.37s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 272/279 [10:42<00:16,  2.36s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  98%|██████▊| 273/279 [10:44<00:14,  2.36s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  98%|██████▊| 274/279 [10:45<00:11,  2.36s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 275/279 [10:46<00:09,  2.35s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 276/279 [10:47<00:07,  2.35s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 277/279 [10:49<00:04,  2.34s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10: 100%|██████▉| 278/279 [10:50<00:02,  2.34s/it, loss=0.662, v_num=7-29]\u001b[A[NeMo W 2022-12-24 06:55:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10: 100%|███████| 279/279 [10:51<00:00,  2.34s/it, loss=0.662, v_num=7-29]\u001b[A\n",
      "Epoch 10: 100%|███████| 279/279 [10:51<00:00,  2.34s/it, loss=0.662, v_num=7-29]Epoch 10, global step 2948: 'val_loss' reached 7.92461 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=7.9246-epoch=10.ckpt' as top 3\n",
      "Epoch 11:  96%|██████▋| 268/279 [10:33<00:26,  2.37s/it, loss=0.655, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 07:06:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.655, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:06:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.655, v_num=7-29]\u001b[A\n",
      "Epoch 11: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.655, v_num=7-29]Epoch 11, global step 3216: 'val_loss' was not in top 3\n",
      "Epoch 12:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.641, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 07:17:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.641, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:17:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.641, v_num=7-29]\u001b[A\n",
      "Epoch 12: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.641, v_num=7-29]Epoch 12, global step 3484: 'val_loss' was not in top 3\n",
      "Epoch 13:  96%|██████▋| 268/279 [10:33<00:26,  2.37s/it, loss=0.646, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 07:28:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  96%|██████▋| 269/279 [10:36<00:23,  2.36s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|██████▉| 277/279 [10:46<00:04,  2.34s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.646, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:28:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.646, v_num=7-29]\u001b[A\n",
      "Epoch 13: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.646, v_num=7-29]Epoch 13, global step 3752: 'val_loss' was not in top 3\n",
      "Epoch 14:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.634, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 07:38:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:38:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:39:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:39:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.634, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:39:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.634, v_num=7-29]\u001b[A\n",
      "Epoch 14: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.634, v_num=7-29]Epoch 14, global step 4020: 'val_loss' reached 7.53329 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=7.5333-epoch=14.ckpt' as top 3\n",
      "Epoch 15:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.624, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 07:49:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15: 100%|██████▉| 278/279 [10:46<00:02,  2.32s/it, loss=0.624, v_num=7-29]\u001b[A[NeMo W 2022-12-24 07:49:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.624, v_num=7-29]\u001b[A\n",
      "Epoch 15: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.624, v_num=7-29]Epoch 15, global step 4288: 'val_loss' was not in top 3\n",
      "Epoch 16:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.605, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 08:00:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.605, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:00:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.605, v_num=7-29]\u001b[A\n",
      "Epoch 16: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.605, v_num=7-29]Epoch 16, global step 4556: 'val_loss' was not in top 3\n",
      "Epoch 17:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.599, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 08:11:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.599, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:11:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.599, v_num=7-29]\u001b[A\n",
      "Epoch 17: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.599, v_num=7-29]Epoch 17, global step 4824: 'val_loss' was not in top 3\n",
      "Epoch 18:  96%|██████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.587, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 08:22:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.587, v_num=7-29][NeMo W 2022-12-24 08:22:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 270/279 [10:39<00:21,  2.37s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  98%|██████▊| 273/279 [10:43<00:14,  2.36s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 276/279 [10:47<00:07,  2.34s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18: 100%|██████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.587, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:22:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.587, v_num=7-29]\u001b[A\n",
      "Epoch 18: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.587, v_num=7-29]Epoch 18, global step 5092: 'val_loss' was not in top 3\n",
      "Epoch 19:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.588, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 08:32:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.588, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:33:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.588, v_num=7-29]\u001b[A\n",
      "Epoch 19: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.588, v_num=7-29]Epoch 19, global step 5360: 'val_loss' was not in top 3\n",
      "Epoch 20:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.581, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 08:43:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:43:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:44:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.581, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:44:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.581, v_num=7-29]\u001b[A\n",
      "Epoch 20: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.581, v_num=7-29]Epoch 20, global step 5628: 'val_loss' was not in top 3\n",
      "Epoch 21:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.571, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 08:54:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.571, v_num=7-29]\u001b[A[NeMo W 2022-12-24 08:54:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.571, v_num=7-29]\u001b[A\n",
      "Epoch 21: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.571, v_num=7-29]Epoch 21, global step 5896: 'val_loss' was not in top 3\n",
      "Epoch 22:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.576, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 09:05:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.576, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:05:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.576, v_num=7-29]\u001b[A\n",
      "Epoch 22: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.576, v_num=7-29]\u001b[AEpoch 22, global step 6164: 'val_loss' was not in top 3\n",
      "Epoch 23:  96%|██████▋| 268/279 [10:30<00:25,  2.35s/it, loss=0.552, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 09:16:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  96%|██████▋| 269/279 [10:33<00:23,  2.35s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 270/279 [10:34<00:21,  2.35s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 271/279 [10:35<00:18,  2.35s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 272/279 [10:37<00:16,  2.34s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  98%|██████▊| 273/279 [10:38<00:14,  2.34s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  98%|██████▊| 274/279 [10:39<00:11,  2.34s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 276/279 [10:42<00:06,  2.33s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 277/279 [10:43<00:04,  2.32s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.552, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:16:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23: 100%|███████| 279/279 [10:46<00:00,  2.32s/it, loss=0.552, v_num=7-29]\u001b[A\n",
      "Epoch 23: 100%|███████| 279/279 [10:46<00:00,  2.32s/it, loss=0.552, v_num=7-29]Epoch 23, global step 6432: 'val_loss' was not in top 3\n",
      "Epoch 24:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.569, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 09:27:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.569, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:27:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.569, v_num=7-29]\u001b[A\n",
      "Epoch 24: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.569, v_num=7-29]Epoch 24, global step 6700: 'val_loss' was not in top 3\n",
      "Epoch 25:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.551, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 09:37:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:37:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:37:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:37:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:37:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:38:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:38:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:38:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:38:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:38:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.551, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:38:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.551, v_num=7-29]\u001b[A\n",
      "Epoch 25: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.551, v_num=7-29]Epoch 25, global step 6968: 'val_loss' was not in top 3\n",
      "Epoch 26:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.558, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 09:48:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.558, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:48:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.558, v_num=7-29]\u001b[A\n",
      "Epoch 26: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.558, v_num=7-29]Epoch 26, global step 7236: 'val_loss' was not in top 3\n",
      "Epoch 27:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.549, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 09:59:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|██████▊| 271/279 [10:38<00:18,  2.35s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.549, v_num=7-29]\u001b[A[NeMo W 2022-12-24 09:59:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.549, v_num=7-29]\u001b[A\n",
      "Epoch 27: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.549, v_num=7-29]Epoch 27, global step 7504: 'val_loss' was not in top 3\n",
      "Epoch 28:  96%|██████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.544, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 10:10:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|██████▊| 270/279 [10:39<00:21,  2.37s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  98%|██████▊| 273/279 [10:43<00:14,  2.36s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|██████▉| 276/279 [10:47<00:07,  2.34s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28: 100%|██████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:10:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.544, v_num=7-29]\u001b[A\n",
      "Epoch 28: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.544, v_num=7-29]Epoch 28, global step 7772: 'val_loss' was not in top 3\n",
      "Epoch 29:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.555, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 10:21:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.555, v_num=7-29][NeMo W 2022-12-24 10:21:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.555, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:21:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.555, v_num=7-29]\u001b[A\n",
      "Epoch 29: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.555, v_num=7-29]Epoch 29, global step 8040: 'val_loss' was not in top 3\n",
      "Epoch 30:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.534, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 10:32:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.534, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:32:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.534, v_num=7-29]\u001b[A\n",
      "Epoch 30: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.534, v_num=7-29]Epoch 30, global step 8308: 'val_loss' was not in top 3\n",
      "Epoch 31:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.544, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 10:42:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:42:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:42:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:42:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:42:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:42:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:43:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:43:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:43:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:43:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.544, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:43:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.544, v_num=7-29]\u001b[A\n",
      "Epoch 31: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.544, v_num=7-29]Epoch 31, global step 8576: 'val_loss' was not in top 3\n",
      "Epoch 32:  96%|██████▋| 268/279 [10:33<00:26,  2.37s/it, loss=0.518, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 10:53:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  99%|██████▉| 277/279 [10:46<00:04,  2.34s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.518, v_num=7-29]\u001b[A[NeMo W 2022-12-24 10:53:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.518, v_num=7-29]\u001b[A\n",
      "Epoch 32: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.518, v_num=7-29]Epoch 32, global step 8844: 'val_loss' was not in top 3\n",
      "Epoch 33:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.529, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 11:04:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.529, v_num=7-29][NeMo W 2022-12-24 11:04:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.529, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:04:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.529, v_num=7-29]\u001b[A\n",
      "Epoch 33: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.529, v_num=7-29]Epoch 33, global step 9112: 'val_loss' was not in top 3\n",
      "Epoch 34:  96%|██████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.525, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 11:15:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  97%|██████▊| 270/279 [10:39<00:21,  2.37s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  98%|██████▊| 273/279 [10:43<00:14,  2.36s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  99%|██████▉| 276/279 [10:47<00:07,  2.34s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34: 100%|██████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.525, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:15:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.525, v_num=7-29]\u001b[A\n",
      "Epoch 34: 100%|███████| 279/279 [10:51<00:00,  2.33s/it, loss=0.525, v_num=7-29]Epoch 34, global step 9380: 'val_loss' was not in top 3\n",
      "Epoch 35:  96%|██████▋| 268/279 [10:33<00:26,  2.37s/it, loss=0.524, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 11:26:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  97%|██████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  98%|██████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.524, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:26:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.524, v_num=7-29]\u001b[A\n",
      "Epoch 35: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.524, v_num=7-29]Epoch 35, global step 9648: 'val_loss' was not in top 3\n",
      "Epoch 37:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.507, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 11:47:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:47:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:47:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:47:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  99%|██████▉| 277/279 [10:46<00:04,  2.34s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.507, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:48:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.507, v_num=7-29]\u001b[A\n",
      "Epoch 37: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.507, v_num=7-29]Epoch 37, global step 10184: 'val_loss' was not in top 3\n",
      "Epoch 38:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.499, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 11:58:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 11:58:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.499, v_num=7-29]\u001b[A\n",
      "Epoch 38: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.499, v_num=7-29]Epoch 38, global step 10452: 'val_loss' was not in top 3\n",
      "Epoch 39:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.499, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 12:09:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  96%|██████▋| 269/279 [10:36<00:23,  2.36s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.499, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:09:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.499, v_num=7-29]\u001b[A\n",
      "Epoch 39: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.499, v_num=7-29]Epoch 39, global step 10720: 'val_loss' was not in top 3\n",
      "Epoch 40:  96%|████████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.5, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 12:20:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  96%|████████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  97%|████████▋| 270/279 [10:38<00:21,  2.36s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  97%|████████▋| 271/279 [10:39<00:18,  2.36s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  97%|████████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  98%|████████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  98%|████████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  99%|████████▊| 275/279 [10:45<00:09,  2.35s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  99%|████████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  99%|████████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40: 100%|████████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.5, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:20:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40: 100%|█████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.5, v_num=7-29]\u001b[A\n",
      "Epoch 40: 100%|█████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.5, v_num=7-29]Epoch 40, global step 10988: 'val_loss' was not in top 3\n",
      "Epoch 41:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.495, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 12:31:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  97%|██████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.495, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:31:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.495, v_num=7-29]\u001b[A\n",
      "Epoch 41: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.495, v_num=7-29]Epoch 41, global step 11256: 'val_loss' was not in top 3\n",
      "Epoch 42:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.484, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 12:42:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.484, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:42:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.484, v_num=7-29]\u001b[A\n",
      "Epoch 42: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.484, v_num=7-29]Epoch 42, global step 11524: 'val_loss' was not in top 3\n",
      "Epoch 43:  96%|██████▋| 268/279 [10:35<00:26,  2.37s/it, loss=0.468, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 12:52:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:52:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  97%|██████▊| 270/279 [10:38<00:21,  2.37s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  98%|██████▊| 273/279 [10:42<00:14,  2.36s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43: 100%|██████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.468, v_num=7-29]\u001b[A[NeMo W 2022-12-24 12:53:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.468, v_num=7-29]\u001b[A\n",
      "Epoch 43: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.468, v_num=7-29]Epoch 43, global step 11792: 'val_loss' was not in top 3\n",
      "Epoch 44:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.487, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 13:03:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:03:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.487, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:04:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.487, v_num=7-29]\u001b[A\n",
      "Epoch 44: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.487, v_num=7-29]Epoch 44, global step 12060: 'val_loss' was not in top 3\n",
      "Epoch 45:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.48, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 13:14:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  96%|███████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  97%|███████▋| 270/279 [10:35<00:21,  2.36s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  97%|███████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  98%|███████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  99%|███████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  99%|███████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.48, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:14:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45: 100%|███████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.48, v_num=7-29][NeMo W 2022-12-24 13:14:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.48, v_num=7-29]\u001b[A\n",
      "Epoch 45: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.48, v_num=7-29]Epoch 45, global step 12328: 'val_loss' was not in top 3\n",
      "Epoch 46:  96%|██████▋| 268/279 [10:31<00:25,  2.35s/it, loss=0.473, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 13:25:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  96%|██████▋| 269/279 [10:33<00:23,  2.35s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  97%|██████▊| 270/279 [10:34<00:21,  2.35s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  97%|██████▊| 272/279 [10:37<00:16,  2.34s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  98%|██████▊| 273/279 [10:38<00:14,  2.34s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  99%|██████▉| 276/279 [10:42<00:06,  2.33s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.473, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:25:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46: 100%|███████| 279/279 [10:46<00:00,  2.32s/it, loss=0.473, v_num=7-29]\u001b[A\n",
      "Epoch 46: 100%|███████| 279/279 [10:46<00:00,  2.32s/it, loss=0.473, v_num=7-29]Epoch 46, global step 12596: 'val_loss' was not in top 3\n",
      "Epoch 47:  96%|███████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.47, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 13:36:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  96%|███████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  97%|███████▋| 270/279 [10:35<00:21,  2.35s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  97%|███████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  97%|███████▊| 272/279 [10:37<00:16,  2.34s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  98%|███████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  98%|███████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  99%|███████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  99%|███████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  99%|███████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47: 100%|███████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.47, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:36:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.47, v_num=7-29]\u001b[A\n",
      "Epoch 47: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.47, v_num=7-29]Epoch 47, global step 12864: 'val_loss' was not in top 3\n",
      "Epoch 48:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.46, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 13:46:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  96%|███████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:46:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  97%|███████▋| 270/279 [10:35<00:21,  2.35s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  97%|███████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  98%|███████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  99%|███████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  99%|███████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48: 100%|███████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.46, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:47:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.46, v_num=7-29]\u001b[A\n",
      "Epoch 48: 100%|████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.46, v_num=7-29]Epoch 48, global step 13132: 'val_loss' was not in top 3\n",
      "Epoch 49:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.457, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 13:57:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:57:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.457, v_num=7-29]\u001b[A[NeMo W 2022-12-24 13:58:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.457, v_num=7-29]\u001b[A\n",
      "Epoch 49: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.457, v_num=7-29]Epoch 49, global step 13400: 'val_loss' was not in top 3\n",
      "Epoch 50:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.459, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 14:08:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  97%|██████▊| 271/279 [10:38<00:18,  2.35s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:08:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.459, v_num=7-29]\u001b[A\n",
      "Epoch 50: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.459, v_num=7-29]Epoch 50, global step 13668: 'val_loss' was not in top 3\n",
      "Epoch 51:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.452, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 14:19:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:19:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.452, v_num=7-29]\u001b[A\n",
      "Epoch 51: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.452, v_num=7-29]Epoch 51, global step 13936: 'val_loss' was not in top 3\n",
      "Epoch 52:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.455, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 14:30:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.455, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:30:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.455, v_num=7-29]\u001b[A\n",
      "Epoch 52: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.455, v_num=7-29]Epoch 52, global step 14204: 'val_loss' was not in top 3\n",
      "Epoch 53:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.459, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 14:41:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.459, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:41:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.459, v_num=7-29]\u001b[A\n",
      "Epoch 53: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.459, v_num=7-29]Epoch 53, global step 14472: 'val_loss' was not in top 3\n",
      "Epoch 54:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.452, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 14:51:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:51:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  97%|██████▊| 270/279 [10:38<00:21,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:51:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:51:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  97%|██████▊| 272/279 [10:40<00:16,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:51:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  98%|██████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:52:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:52:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:52:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:52:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:52:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 14:52:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A\n",
      "Epoch 54: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.452, v_num=7-29]Epoch 54, global step 14740: 'val_loss' was not in top 3\n",
      "Epoch 55:  96%|███████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.45, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 15:02:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  96%|███████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  97%|███████▋| 270/279 [10:38<00:21,  2.36s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  97%|███████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  97%|███████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  98%|███████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  98%|███████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  99%|███████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  99%|███████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  99%|███████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55: 100%|███████▉| 278/279 [10:49<00:02,  2.33s/it, loss=0.45, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:02:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.45, v_num=7-29]\u001b[A\n",
      "Epoch 55: 100%|████████| 279/279 [10:50<00:00,  2.33s/it, loss=0.45, v_num=7-29]Epoch 55, global step 15008: 'val_loss' was not in top 3\n",
      "Epoch 56:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.444, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 15:13:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.444, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:13:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.444, v_num=7-29]\u001b[A\n",
      "Epoch 56: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.444, v_num=7-29]Epoch 56, global step 15276: 'val_loss' was not in top 3\n",
      "Epoch 57:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.452, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 15:24:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.452, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:24:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.452, v_num=7-29]\u001b[A\n",
      "Epoch 57: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.452, v_num=7-29]Epoch 57, global step 15544: 'val_loss' was not in top 3\n",
      "Epoch 58:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.445, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 15:35:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.445, v_num=7-29]\u001b[A[NeMo W 2022-12-24 15:35:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 58: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.445, v_num=7-29]\u001b[A\n",
      "Epoch 58: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.445, v_num=7-29]\u001b[A\n",
      "Epoch 58: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.445, v_num=7-29]Epoch 58, global step 15812: 'val_loss' was not in top 3\n",
      "Epoch 59:  42%|██▉    | 117/279 [04:36<06:23,  2.37s/it, loss=0.442, v_num=7-29]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.428, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 18:17:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  96%|██████▋| 269/279 [10:36<00:23,  2.36s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  99%|██████▉| 277/279 [10:46<00:04,  2.34s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.428, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:17:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.428, v_num=7-29]\u001b[A\n",
      "Epoch 73: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.428, v_num=7-29]Epoch 73, global step 19832: 'val_loss' was not in top 3\n",
      "Epoch 74:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.416, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 18:28:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:28:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 74: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.416, v_num=7-29]\u001b[A\n",
      "Epoch 74: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.416, v_num=7-29]Epoch 74, global step 20100: 'val_loss' was not in top 3\n",
      "Epoch 75:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.429, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 18:39:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.429, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:39:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 75: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.429, v_num=7-29]\u001b[A\n",
      "Epoch 75: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.429, v_num=7-29]Epoch 75, global step 20368: 'val_loss' reached 7.41417 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=7.4142-epoch=75.ckpt' as top 3\n",
      "Epoch 76:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.418, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 18:50:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.418, v_num=7-29][NeMo W 2022-12-24 18:50:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.418, v_num=7-29]\u001b[A[NeMo W 2022-12-24 18:50:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 76: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.418, v_num=7-29]\u001b[A\n",
      "Epoch 76: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.418, v_num=7-29]Epoch 76, global step 20636: 'val_loss' was not in top 3\n",
      "Epoch 77:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.421, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 19:00:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:00:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:00:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:00:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:00:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:00:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:01:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:01:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:01:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:01:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.421, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:01:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.421, v_num=7-29]\u001b[A\n",
      "Epoch 77: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.421, v_num=7-29]Epoch 77, global step 20904: 'val_loss' was not in top 3\n",
      "Epoch 78:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.415, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 19:11:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  97%|██████▊| 270/279 [10:35<00:21,  2.36s/it, loss=0.415, v_num=7-29]\u001b[A\n",
      "Epoch 78:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.415, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:11:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.415, v_num=7-29]\u001b[A\n",
      "Epoch 78: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.415, v_num=7-29]Epoch 78, global step 21172: 'val_loss' was not in top 3\n",
      "Epoch 79:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.416, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 19:22:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.416, v_num=7-29]\u001b[A\n",
      "Epoch 79:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.416, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:22:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 79: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.416, v_num=7-29]\u001b[A\n",
      "Epoch 79: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.416, v_num=7-29]Epoch 79, global step 21440: 'val_loss' was not in top 3\n",
      "Epoch 80:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.412, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 19:33:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  97%|██████▊| 270/279 [10:35<00:21,  2.36s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.412, v_num=7-29][NeMo W 2022-12-24 19:33:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.412, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:33:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 80: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.412, v_num=7-29]\u001b[A\n",
      "Epoch 80: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.412, v_num=7-29]Epoch 80, global step 21708: 'val_loss' was not in top 3\n",
      "Epoch 81:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.405, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 19:44:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.405, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:44:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 81: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.405, v_num=7-29]\u001b[A\n",
      "Epoch 81: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.405, v_num=7-29]Epoch 81, global step 21976: 'val_loss' was not in top 3\n",
      "Epoch 82:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.413, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 19:54:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:54:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:54:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.413, v_num=7-29]\u001b[A[NeMo W 2022-12-24 19:55:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.413, v_num=7-29]\u001b[A\n",
      "Epoch 82: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.413, v_num=7-29]\u001b[A\n",
      "Epoch 82: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.413, v_num=7-29]Epoch 82, global step 22244: 'val_loss' was not in top 3\n",
      "Epoch 83:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.406, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 20:05:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  97%|██████▊| 271/279 [10:38<00:18,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:05:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 83: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.406, v_num=7-29]\u001b[A\n",
      "Epoch 83: 100%|███████| 279/279 [10:48<00:00,  2.33s/it, loss=0.406, v_num=7-29]Epoch 83, global step 22512: 'val_loss' was not in top 3\n",
      "Epoch 84:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.41, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 20:16:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  96%|███████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  97%|███████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  99%|███████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  99%|███████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84: 100%|███████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.41, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:16:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.41, v_num=7-29]\u001b[A\n",
      "Epoch 84: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.41, v_num=7-29]Epoch 84, global step 22780: 'val_loss' reached 7.22195 (best 5.45253), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_04-47-29/checkpoints/Tacotron2--val_loss=7.2219-epoch=84.ckpt' as top 3\n",
      "Epoch 85:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.406, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 20:27:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  96%|██████▋| 269/279 [10:38<00:23,  2.37s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  97%|██████▊| 270/279 [10:39<00:21,  2.37s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  97%|██████▊| 271/279 [10:40<00:18,  2.37s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  97%|██████▊| 272/279 [10:42<00:16,  2.36s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  98%|██████▊| 273/279 [10:43<00:14,  2.36s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  99%|██████▉| 275/279 [10:46<00:09,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  99%|██████▉| 276/279 [10:47<00:07,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85:  99%|██████▉| 277/279 [10:49<00:04,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85: 100%|██████▉| 278/279 [10:50<00:02,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:27:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 85: 100%|███████| 279/279 [10:51<00:00,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A\n",
      "Epoch 85: 100%|███████| 279/279 [10:51<00:00,  2.34s/it, loss=0.406, v_num=7-29]Epoch 85, global step 23048: 'val_loss' was not in top 3\n",
      "Epoch 86:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.406, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 20:38:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  97%|██████▊| 270/279 [10:38<00:21,  2.37s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  97%|██████▊| 271/279 [10:40<00:18,  2.36s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  98%|██████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  98%|██████▊| 274/279 [10:44<00:11,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86:  99%|██████▉| 277/279 [10:48<00:04,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86: 100%|██████▉| 278/279 [10:49<00:02,  2.34s/it, loss=0.406, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:38:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 86: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.406, v_num=7-29]\u001b[A\n",
      "Epoch 86: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.406, v_num=7-29]Epoch 86, global step 23316: 'val_loss' was not in top 3\n",
      "Epoch 87:  96%|██████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.398, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 20:49:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  98%|██████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 20:49:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 87: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.398, v_num=7-29]\u001b[A\n",
      "Epoch 87: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.398, v_num=7-29]Epoch 87, global step 23584: 'val_loss' was not in top 3\n",
      "Epoch 88:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.398, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 20:59:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  96%|██████▋| 269/279 [10:37<00:23,  2.37s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  97%|██████▊| 270/279 [10:38<00:21,  2.36s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  97%|██████▊| 272/279 [10:41<00:16,  2.36s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  98%|██████▊| 273/279 [10:42<00:14,  2.35s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  99%|██████▉| 275/279 [10:45<00:09,  2.35s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  99%|██████▉| 276/279 [10:46<00:07,  2.34s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88: 100%|██████▉| 278/279 [10:49<00:02,  2.33s/it, loss=0.398, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:00:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 88: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.398, v_num=7-29]\u001b[A\n",
      "Epoch 88: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.398, v_num=7-29]Epoch 88, global step 23852: 'val_loss' was not in top 3\n",
      "Epoch 89:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.401, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 21:10:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:10:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A\n",
      "Epoch 89: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.401, v_num=7-29]\u001b[A\n",
      "Epoch 89: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.401, v_num=7-29]Epoch 89, global step 24120: 'val_loss' was not in top 3\n",
      "Epoch 90:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.401, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 21:21:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  96%|██████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  97%|██████▊| 272/279 [10:37<00:16,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:21:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.401, v_num=7-29]\u001b[A\n",
      "Epoch 90: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.401, v_num=7-29]Epoch 90, global step 24388: 'val_loss' was not in top 3\n",
      "Epoch 91:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.408, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 21:32:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.408, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:32:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.408, v_num=7-29]\u001b[A\n",
      "Epoch 91: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.408, v_num=7-29]Epoch 91, global step 24656: 'val_loss' was not in top 3\n",
      "Epoch 92:  96%|██████▋| 268/279 [10:30<00:25,  2.35s/it, loss=0.399, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 21:43:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  96%|██████▋| 269/279 [10:32<00:23,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  97%|██████▊| 270/279 [10:33<00:21,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  97%|██████▊| 271/279 [10:35<00:18,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  97%|██████▊| 272/279 [10:36<00:16,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  98%|██████▊| 273/279 [10:37<00:14,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  98%|██████▊| 274/279 [10:39<00:11,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  99%|██████▉| 275/279 [10:40<00:09,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  99%|██████▉| 276/279 [10:41<00:06,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92:  99%|██████▉| 277/279 [10:43<00:04,  2.32s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92: 100%|██████▉| 278/279 [10:44<00:02,  2.32s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:43:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 92: 100%|███████| 279/279 [10:45<00:00,  2.31s/it, loss=0.399, v_num=7-29]\u001b[A\n",
      "Epoch 92: 100%|███████| 279/279 [10:45<00:00,  2.31s/it, loss=0.399, v_num=7-29]Epoch 92, global step 24924: 'val_loss' was not in top 3\n",
      "Epoch 93:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.402, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 21:53:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  96%|██████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:53:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  97%|██████▊| 272/279 [10:38<00:16,  2.35s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  99%|██████▉| 275/279 [10:42<00:09,  2.34s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93: 100%|██████▉| 278/279 [10:46<00:02,  2.33s/it, loss=0.402, v_num=7-29]\u001b[A[NeMo W 2022-12-24 21:54:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 93: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.402, v_num=7-29]\u001b[A\n",
      "Epoch 93: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.402, v_num=7-29]Epoch 93, global step 25192: 'val_loss' was not in top 3\n",
      "Epoch 94:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.401, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 22:04:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  99%|██████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:04:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.401, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:05:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.401, v_num=7-29]\u001b[A\n",
      "Epoch 94: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.401, v_num=7-29]Epoch 94, global step 25460: 'val_loss' was not in top 3\n",
      "Epoch 95:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.393, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 22:15:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  96%|██████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  97%|██████▊| 270/279 [10:34<00:21,  2.35s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  97%|██████▊| 272/279 [10:37<00:16,  2.34s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  98%|██████▊| 273/279 [10:38<00:14,  2.34s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.393, v_num=7-29][NeMo W 2022-12-24 22:15:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  99%|██████▉| 276/279 [10:42<00:06,  2.33s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.393, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:15:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 95: 100%|███████| 279/279 [10:46<00:00,  2.32s/it, loss=0.393, v_num=7-29]\u001b[A\n",
      "Epoch 95: 100%|███████| 279/279 [10:46<00:00,  2.32s/it, loss=0.393, v_num=7-29]Epoch 95, global step 25728: 'val_loss' was not in top 3\n",
      "Epoch 96:  96%|██████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.399, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 22:26:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  96%|██████▋| 269/279 [10:34<00:23,  2.36s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  97%|██████▊| 270/279 [10:36<00:21,  2.36s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  97%|██████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  98%|██████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  98%|██████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  99%|██████▉| 276/279 [10:44<00:07,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  99%|██████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:26:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.399, v_num=7-29]\u001b[A\n",
      "Epoch 96: 100%|███████| 279/279 [10:48<00:00,  2.32s/it, loss=0.399, v_num=7-29]Epoch 96, global step 25996: 'val_loss' was not in top 3\n",
      "Epoch 97:  96%|████████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.4, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 22:37:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  96%|████████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  97%|████████▋| 270/279 [10:35<00:21,  2.35s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  97%|████████▋| 271/279 [10:36<00:18,  2.35s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  97%|████████▊| 272/279 [10:37<00:16,  2.34s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  98%|████████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  98%|████████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  99%|████████▊| 275/279 [10:42<00:09,  2.33s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  99%|████████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97:  99%|████████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97: 100%|████████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.4, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:37:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 97: 100%|█████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.4, v_num=7-29]\u001b[A\n",
      "Epoch 97: 100%|█████████| 279/279 [10:47<00:00,  2.32s/it, loss=0.4, v_num=7-29]Epoch 97, global step 26264: 'val_loss' was not in top 3\n",
      "Epoch 98:  96%|██████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.399, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 22:48:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  96%|██████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  97%|██████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  97%|██████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  98%|██████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  99%|██████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98:  99%|██████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98: 100%|██████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:48:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 98: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.399, v_num=7-29]\u001b[A\n",
      "Epoch 98: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.399, v_num=7-29]Epoch 98, global step 26532: 'val_loss' was not in top 3\n",
      "Epoch 99:  96%|██████▋| 268/279 [10:34<00:26,  2.37s/it, loss=0.391, v_num=7-29]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 22:58:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  96%|██████▋| 269/279 [10:36<00:23,  2.37s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:58:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  97%|██████▊| 270/279 [10:37<00:21,  2.36s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:58:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  97%|██████▊| 271/279 [10:39<00:18,  2.36s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:58:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  97%|██████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.391, v_num=7-29][NeMo W 2022-12-24 22:58:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  98%|██████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:58:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  98%|██████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:58:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  99%|██████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:59:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  99%|██████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:59:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99:  99%|██████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:59:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99: 100%|██████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.391, v_num=7-29]\u001b[A[NeMo W 2022-12-24 22:59:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 99: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.391, v_num=7-29]\u001b[A\n",
      "Epoch 99: 100%|███████| 279/279 [10:49<00:00,  2.33s/it, loss=0.391, v_num=7-29]Epoch 99, global step 26800: 'val_loss' was not in top 3\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "Epoch 99: 100%|███████| 279/279 [10:50<00:00,  2.33s/it, loss=0.391, v_num=7-29]\n"
     ]
    }
   ],
   "source": [
    "!(python tacotron2.py \\\n",
    "  train_dataset=trn_dataset_LJ.json \\\n",
    "  validation_datasets=val_dataset_LJ.json \\\n",
    "  trainer.max_epochs=100 \\\n",
    "  trainer.accelerator=null \\\n",
    "  trainer.check_val_every_n_epoch=1 \\\n",
    " +trainer.gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c80d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-24 22:59:44 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-12-24 23:00:00 experimental:27] Module <class 'nemo.collections.common.tokenizers.text_to_speech.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:00 experimental:27] Module <class 'nemo.collections.tts.models.radtts.RadTTSModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:00 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "      ret = run_job(\n",
      "    \n",
      "[NeMo W 2022-12-24 23:00:00 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "      rank_zero_deprecation(\n",
      "    \n",
      "[NeMo W 2022-12-24 23:00:00 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:461: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "      rank_zero_warn(\n",
      "    \n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo I 2022-12-24 23:00:00 exp_manager:361] Experiments will be logged at /home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00\n",
      "[NeMo I 2022-12-24 23:00:00 exp_manager:766] TensorboardLogger has been set up\n",
      "[NeMo W 2022-12-24 23:00:00 exp_manager:1045] The checkpoint callback was told to monitor a validation value and trainer's max_steps was set to -1. Please ensure that max_steps will run for at least 1 epochs to ensure that checkpointing will not error out.\n",
      "[NeMo I 2022-12-24 23:00:03 tokenize_and_classify:87] Creating ClassifyFst grammars.\n",
      "[NeMo W 2022-12-24 23:00:35 experimental:27] Module <class 'nemo_text_processing.g2p.modules.IPAG2P'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:36 modules:95] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2022-12-24 23:00:37 experimental:27] Module <class 'nemo.collections.asr.models.audio_to_audio_model.AudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:38 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:39 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/jit/annotations.py:309: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.\n",
      "      warnings.warn(\"TorchScript will treat type annotations of Tensor \"\n",
      "    \n",
      "[NeMo W 2022-12-24 23:00:39 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.BaseAudioDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:39 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:39 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithReferenceDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:39 experimental:27] Module <class 'nemo.collections.asr.data.audio_to_audio.AudioToTargetWithEmbeddingDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-12-24 23:00:39 experimental:27] Module <class 'nemo.collections.asr.models.enhancement_models.EncMaskDecAudioToAudioModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-12-24 23:00:39 data:217] Loading dataset from trn_dataset_LJ.json.\n",
      "12838it [07:58, 26.85it/s]\n",
      "[NeMo I 2022-12-24 23:08:37 data:254] Loaded dataset with 12838 files.\n",
      "[NeMo I 2022-12-24 23:08:37 data:256] Dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-24 23:08:37 data:358] Pruned 0 files. Final dataset contains 12838 files\n",
      "[NeMo I 2022-12-24 23:08:37 data:360] Pruned 0.00 hours. Final dataset contains 23.45 hours.\n",
      "[NeMo I 2022-12-24 23:08:37 data:217] Loading dataset from val_dataset_LJ.json.\n",
      "262it [00:17, 14.98it/s]\n",
      "[NeMo I 2022-12-24 23:08:55 data:254] Loaded dataset with 262 files.\n",
      "[NeMo I 2022-12-24 23:08:55 data:256] Dataset contains 0.47 hours.\n",
      "[NeMo I 2022-12-24 23:08:55 data:358] Pruned 0 files. Final dataset contains 262 files\n",
      "[NeMo I 2022-12-24 23:08:55 data:360] Pruned 0.00 hours. Final dataset contains 0.47 hours.\n",
      "[NeMo W 2022-12-24 23:08:55 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "      warnings.warn(_create_warning_msg(\n",
      "    \n",
      "[NeMo I 2022-12-24 23:08:55 features:267] PADDING: 16\n",
      "[NeMo I 2022-12-24 23:08:55 features:275] STFT using exact pad\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-12-24 23:08:58 modelPT:616] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        capturable: False\n",
      "        differentiable: False\n",
      "        eps: 1e-08\n",
      "        foreach: None\n",
      "        fused: False\n",
      "        lr: 0.001\n",
      "        maximize: False\n",
      "        weight_decay: 1e-06\n",
      "    )\n",
      "[NeMo I 2022-12-24 23:08:58 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f95bcbc2f70>\" \n",
      "    will be used during training (effective maximum steps = 53600) - \n",
      "    Parameters : \n",
      "    (min_lr: 1.0e-05\n",
      "    max_steps: 53600\n",
      "    )\n",
      "\n",
      "  | Name                       | Type               | Params\n",
      "------------------------------------------------------------------\n",
      "0 | audio_to_melspec_precessor | FilterbankFeatures | 0     \n",
      "1 | text_embedding             | Embedding          | 58.4 K\n",
      "2 | encoder                    | Encoder            | 5.5 M \n",
      "3 | decoder                    | Decoder            | 18.3 M\n",
      "4 | postnet                    | Postnet            | 4.3 M \n",
      "5 | loss                       | Tacotron2Loss      | 0     \n",
      "------------------------------------------------------------------\n",
      "28.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 M    Total params\n",
      "112.703   Total estimated model params size (MB)\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s][NeMo W 2022-12-24 23:09:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "Sanity Checking DataLoader 0:  50%|███████▌       | 1/2 [00:04<00:04,  4.16s/it][NeMo W 2022-12-24 23:09:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "Sanity Checking DataLoader 0: 100%|███████████████| 2/2 [00:05<00:00,  2.71s/it][NeMo W 2022-12-24 23:09:06 nemo_logging:349] /home/aifree910884/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/279 [00:00<?, ?it/s][W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  96%|████████▋| 268/279 [10:39<00:26,  2.39s/it, loss=1.52, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 23:19:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  96%|████████▋| 269/279 [10:41<00:23,  2.39s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 270/279 [10:43<00:21,  2.38s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▋| 271/279 [10:44<00:19,  2.38s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  97%|████████▊| 272/279 [10:45<00:16,  2.37s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 273/279 [10:47<00:14,  2.37s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  98%|████████▊| 274/279 [10:48<00:11,  2.37s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▊| 275/279 [10:49<00:09,  2.36s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 276/279 [10:51<00:07,  2.36s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0:  99%|████████▉| 277/279 [10:52<00:04,  2.36s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:19:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|████████▉| 278/279 [10:53<00:02,  2.35s/it, loss=1.52, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:20:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 0: 100%|█████████| 279/279 [10:55<00:00,  2.35s/it, loss=1.52, v_num=0-00]\u001b[A\n",
      "Epoch 0: 100%|█████████| 279/279 [10:55<00:00,  2.35s/it, loss=1.52, v_num=0-00]Epoch 0, global step 268: 'val_loss' reached 6.65369 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=6.6537-epoch=0.ckpt' as top 3\n",
      "Epoch 1:  96%|████████▋| 268/279 [10:34<00:26,  2.37s/it, loss=1.18, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 23:30:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  96%|████████▋| 269/279 [10:36<00:23,  2.37s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 270/279 [10:38<00:21,  2.36s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▋| 271/279 [10:39<00:18,  2.36s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  97%|████████▊| 272/279 [10:40<00:16,  2.36s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 273/279 [10:42<00:14,  2.35s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  98%|████████▊| 274/279 [10:43<00:11,  2.35s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▊| 275/279 [10:44<00:09,  2.34s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 276/279 [10:46<00:07,  2.34s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1:  99%|████████▉| 277/279 [10:47<00:04,  2.34s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|████████▉| 278/279 [10:48<00:02,  2.33s/it, loss=1.18, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:30:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 1: 100%|█████████| 279/279 [10:50<00:00,  2.33s/it, loss=1.18, v_num=0-00]\u001b[A\n",
      "Epoch 1: 100%|█████████| 279/279 [10:50<00:00,  2.33s/it, loss=1.18, v_num=0-00]Epoch 1, global step 536: 'val_loss' reached 8.21050 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=8.2105-epoch=1.ckpt' as top 3\n",
      "Epoch 2:  96%|███████▋| 268/279 [10:32<00:25,  2.36s/it, loss=0.949, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 23:41:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|███████▊| 271/279 [10:37<00:18,  2.35s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|███████▊| 273/279 [10:40<00:14,  2.35s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  98%|███████▊| 274/279 [10:41<00:11,  2.34s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|███████▉| 276/279 [10:44<00:07,  2.34s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2:  99%|███████▉| 277/279 [10:45<00:04,  2.33s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.949, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:41:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 2: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.949, v_num=0-00]\u001b[A\n",
      "Epoch 2: 100%|████████| 279/279 [10:48<00:00,  2.32s/it, loss=0.949, v_num=0-00]Epoch 2, global step 804: 'val_loss' reached 13.24322 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=13.2432-epoch=2.ckpt' as top 3\n",
      "Epoch 3:  96%|███████▋| 268/279 [10:33<00:26,  2.36s/it, loss=0.854, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-24 23:52:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  96%|███████▋| 269/279 [10:36<00:23,  2.36s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▋| 270/279 [10:37<00:21,  2.36s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  97%|███████▊| 272/279 [10:40<00:16,  2.35s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  98%|███████▊| 274/279 [10:43<00:11,  2.35s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 275/279 [10:44<00:09,  2.34s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3:  99%|███████▉| 277/279 [10:47<00:04,  2.34s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|███████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.854, v_num=0-00]\u001b[A[NeMo W 2022-12-24 23:52:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 3: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.854, v_num=0-00]\u001b[A\n",
      "Epoch 3: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.854, v_num=0-00]Epoch 3, global step 1072: 'val_loss' reached 9.53931 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=9.5393-epoch=3.ckpt' as top 3\n",
      "Epoch 4:  96%|███████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.825, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 00:03:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▋| 270/279 [10:37<00:21,  2.36s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  98%|███████▊| 274/279 [10:42<00:11,  2.35s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4:  99%|███████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|███████▉| 278/279 [10:48<00:02,  2.33s/it, loss=0.825, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:03:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 4: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.825, v_num=0-00]\u001b[A\n",
      "Epoch 4: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.825, v_num=0-00]Epoch 4, global step 1340: 'val_loss' was not in top 3\n",
      "Epoch 5:  96%|███████▋| 268/279 [10:33<00:25,  2.36s/it, loss=0.755, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 00:13:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  96%|███████▋| 269/279 [10:35<00:23,  2.36s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▋| 270/279 [10:36<00:21,  2.36s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 271/279 [10:38<00:18,  2.36s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  97%|███████▊| 272/279 [10:39<00:16,  2.35s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 273/279 [10:41<00:14,  2.35s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  98%|███████▊| 274/279 [10:42<00:11,  2.34s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 275/279 [10:43<00:09,  2.34s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 276/279 [10:45<00:07,  2.34s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5:  99%|███████▉| 277/279 [10:46<00:04,  2.33s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|███████▉| 278/279 [10:47<00:02,  2.33s/it, loss=0.755, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:14:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 5: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.755, v_num=0-00]\u001b[A\n",
      "Epoch 5: 100%|████████| 279/279 [10:49<00:00,  2.33s/it, loss=0.755, v_num=0-00]Epoch 5, global step 1608: 'val_loss' reached 7.33720 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=7.3372-epoch=5.ckpt' as top 3\n",
      "Epoch 6:  96%|███████▋| 268/279 [10:30<00:25,  2.35s/it, loss=0.726, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 00:24:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  96%|███████▋| 269/279 [10:33<00:23,  2.35s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▋| 270/279 [10:34<00:21,  2.35s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 271/279 [10:35<00:18,  2.35s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  97%|███████▊| 272/279 [10:36<00:16,  2.34s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 273/279 [10:38<00:14,  2.34s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  98%|███████▊| 274/279 [10:39<00:11,  2.33s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 275/279 [10:40<00:09,  2.33s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 276/279 [10:42<00:06,  2.33s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6:  99%|███████▉| 277/279 [10:43<00:04,  2.32s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|███████▉| 278/279 [10:44<00:02,  2.32s/it, loss=0.726, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:24:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 6: 100%|████████| 279/279 [10:46<00:00,  2.32s/it, loss=0.726, v_num=0-00]\u001b[A\n",
      "Epoch 6: 100%|████████| 279/279 [10:46<00:00,  2.32s/it, loss=0.726, v_num=0-00]Epoch 6, global step 1876: 'val_loss' was not in top 3\n",
      "Epoch 7:  96%|███████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.715, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 00:35:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  96%|███████▋| 269/279 [10:29<00:23,  2.34s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▋| 270/279 [10:30<00:21,  2.33s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  97%|███████▊| 272/279 [10:33<00:16,  2.33s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 273/279 [10:34<00:13,  2.32s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  98%|███████▊| 274/279 [10:35<00:11,  2.32s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 275/279 [10:37<00:09,  2.32s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 276/279 [10:38<00:06,  2.31s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7:  99%|███████▉| 277/279 [10:39<00:04,  2.31s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|███████▉| 278/279 [10:41<00:02,  2.31s/it, loss=0.715, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:35:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 7: 100%|████████| 279/279 [10:42<00:00,  2.30s/it, loss=0.715, v_num=0-00]\u001b[A\n",
      "Epoch 7: 100%|████████| 279/279 [10:42<00:00,  2.30s/it, loss=0.715, v_num=0-00]Epoch 7, global step 2144: 'val_loss' was not in top 3\n",
      "Epoch 8:  96%|███████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.686, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 00:46:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  96%|███████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▋| 270/279 [10:27<00:20,  2.32s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  97%|███████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  98%|███████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8:  99%|███████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|███████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.686, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:46:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 8: 100%|████████| 279/279 [10:39<00:00,  2.29s/it, loss=0.686, v_num=0-00]\u001b[A\n",
      "Epoch 8: 100%|████████| 279/279 [10:39<00:00,  2.29s/it, loss=0.686, v_num=0-00]Epoch 8, global step 2412: 'val_loss' was not in top 3\n",
      "Epoch 9:  96%|███████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.675, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 00:56:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  96%|███████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▋| 270/279 [10:26<00:20,  2.32s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  97%|███████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  98%|███████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9:  99%|███████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:56:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|███████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.675, v_num=0-00]\u001b[A[NeMo W 2022-12-25 00:57:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 9: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.675, v_num=0-00]\u001b[A\n",
      "Epoch 9: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.675, v_num=0-00]Epoch 9, global step 2680: 'val_loss' was not in top 3\n",
      "Epoch 10:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.662, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 01:07:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  97%|██████▊| 272/279 [10:32<00:16,  2.32s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.662, v_num=0-00][NeMo W 2022-12-25 01:07:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  98%|██████▊| 274/279 [10:34<00:11,  2.32s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10:  99%|██████▉| 277/279 [10:38<00:04,  2.31s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10: 100%|██████▉| 278/279 [10:40<00:02,  2.30s/it, loss=0.662, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:07:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 10: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.662, v_num=0-00]\u001b[A\n",
      "Epoch 10: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.662, v_num=0-00]Epoch 10, global step 2948: 'val_loss' was not in top 3\n",
      "Epoch 11:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.637, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 01:18:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11:  99%|██████▉| 277/279 [10:38<00:04,  2.30s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.637, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:18:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 11: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.637, v_num=0-00]\u001b[A\n",
      "Epoch 11: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.637, v_num=0-00]Epoch 11, global step 3216: 'val_loss' was not in top 3\n",
      "Epoch 12:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.632, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 01:28:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:28:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:29:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:29:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.632, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:29:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 12: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.632, v_num=0-00]\u001b[A\n",
      "Epoch 12: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.632, v_num=0-00]Epoch 12, global step 3484: 'val_loss' was not in top 3\n",
      "Epoch 13:  96%|███████▋| 268/279 [10:23<00:25,  2.32s/it, loss=0.63, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 01:39:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  96%|███████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|███████▋| 270/279 [10:26<00:20,  2.32s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|███████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  97%|███████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  98%|███████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  98%|███████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|███████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|███████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13:  99%|███████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13: 100%|███████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.63, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:39:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 13: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.63, v_num=0-00]\u001b[A\n",
      "Epoch 13: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.63, v_num=0-00]Epoch 13, global step 3752: 'val_loss' was not in top 3\n",
      "Epoch 14:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.618, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 01:50:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.618, v_num=0-00]\u001b[A[NeMo W 2022-12-25 01:50:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 14: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.618, v_num=0-00]\u001b[A\n",
      "Epoch 14: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.618, v_num=0-00]Epoch 14, global step 4020: 'val_loss' was not in top 3\n",
      "Epoch 15:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.604, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 02:00:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:00:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 270/279 [10:27<00:20,  2.33s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:00:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:00:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:00:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:00:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:00:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:01:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:01:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:01:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.604, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:01:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 15: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.604, v_num=0-00]\u001b[A\n",
      "Epoch 15: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.604, v_num=0-00]Epoch 15, global step 4288: 'val_loss' was not in top 3\n",
      "Epoch 16:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.593, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 02:11:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  97%|██████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.593, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:11:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 16: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.593, v_num=0-00]\u001b[A\n",
      "Epoch 16: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.593, v_num=0-00]Epoch 16, global step 4556: 'val_loss' reached 7.82733 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=7.8273-epoch=16.ckpt' as top 3\n",
      "Epoch 17:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.596, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 02:22:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.596, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:22:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 17: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.596, v_num=0-00]\u001b[A\n",
      "Epoch 17: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.596, v_num=0-00]Epoch 17, global step 4824: 'val_loss' was not in top 3\n",
      "Epoch 18:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.588, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 02:32:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:32:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:32:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:32:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:32:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:32:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:32:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:33:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:33:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:33:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.588, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:33:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 18: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.588, v_num=0-00]\u001b[A\n",
      "Epoch 18: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.588, v_num=0-00]Epoch 18, global step 5092: 'val_loss' was not in top 3\n",
      "Epoch 19:  96%|██████▋| 268/279 [10:28<00:25,  2.34s/it, loss=0.574, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 02:43:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  96%|██████▋| 269/279 [10:30<00:23,  2.34s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 270/279 [10:31<00:21,  2.34s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 271/279 [10:33<00:18,  2.34s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  97%|██████▊| 272/279 [10:34<00:16,  2.33s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  98%|██████▊| 273/279 [10:36<00:13,  2.33s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  98%|██████▊| 274/279 [10:37<00:11,  2.33s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 275/279 [10:38<00:09,  2.32s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 276/279 [10:40<00:06,  2.32s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19:  99%|██████▉| 277/279 [10:41<00:04,  2.32s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19: 100%|██████▉| 278/279 [10:42<00:02,  2.31s/it, loss=0.574, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:43:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 19: 100%|███████| 279/279 [10:44<00:00,  2.31s/it, loss=0.574, v_num=0-00]\u001b[A\n",
      "Epoch 19: 100%|███████| 279/279 [10:44<00:00,  2.31s/it, loss=0.574, v_num=0-00]Epoch 19, global step 5360: 'val_loss' was not in top 3\n",
      "Epoch 20:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.572, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 02:54:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 271/279 [10:30<00:18,  2.32s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  98%|██████▊| 274/279 [10:34<00:11,  2.31s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20:  99%|██████▉| 277/279 [10:38<00:04,  2.30s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.572, v_num=0-00]\u001b[A[NeMo W 2022-12-25 02:54:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 20: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.572, v_num=0-00]\u001b[A\n",
      "Epoch 20: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.572, v_num=0-00]Epoch 20, global step 5628: 'val_loss' was not in top 3\n",
      "Epoch 21:  96%|██████▋| 268/279 [10:28<00:25,  2.35s/it, loss=0.563, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 03:05:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  96%|██████▋| 269/279 [10:30<00:23,  2.35s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 270/279 [10:32<00:21,  2.34s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 271/279 [10:33<00:18,  2.34s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  97%|██████▊| 272/279 [10:35<00:16,  2.33s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  98%|██████▊| 273/279 [10:36<00:13,  2.33s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  98%|██████▊| 274/279 [10:37<00:11,  2.33s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 275/279 [10:39<00:09,  2.32s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 276/279 [10:40<00:06,  2.32s/it, loss=0.563, v_num=0-00][NeMo W 2022-12-25 03:05:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21:  99%|██████▉| 277/279 [10:41<00:04,  2.32s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21: 100%|██████▉| 278/279 [10:43<00:02,  2.31s/it, loss=0.563, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:05:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 21: 100%|███████| 279/279 [10:44<00:00,  2.31s/it, loss=0.563, v_num=0-00]\u001b[A\n",
      "Epoch 21: 100%|███████| 279/279 [10:44<00:00,  2.31s/it, loss=0.563, v_num=0-00]Epoch 21, global step 5896: 'val_loss' was not in top 3\n",
      "Epoch 22:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.558, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 03:15:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  96%|██████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  97%|██████▊| 272/279 [10:37<00:16,  2.35s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:15:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:16:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.558, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:16:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 22: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.558, v_num=0-00]\u001b[A\n",
      "Epoch 22: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.558, v_num=0-00]Epoch 22, global step 6164: 'val_loss' was not in top 3\n",
      "Epoch 23:  96%|██████▋| 268/279 [10:25<00:25,  2.34s/it, loss=0.556, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 03:26:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  97%|██████▊| 272/279 [10:32<00:16,  2.32s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  98%|██████▊| 274/279 [10:34<00:11,  2.32s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23:  99%|██████▉| 277/279 [10:38<00:04,  2.31s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23: 100%|██████▉| 278/279 [10:40<00:02,  2.30s/it, loss=0.556, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:26:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 23: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.556, v_num=0-00]\u001b[A\n",
      "Epoch 23: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.556, v_num=0-00]Epoch 23, global step 6432: 'val_loss' was not in top 3\n",
      "Epoch 24:  96%|██████▋| 268/279 [10:27<00:25,  2.34s/it, loss=0.566, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 03:37:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  96%|██████▋| 269/279 [10:29<00:23,  2.34s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 270/279 [10:30<00:21,  2.34s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 271/279 [10:32<00:18,  2.33s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  97%|██████▊| 272/279 [10:33<00:16,  2.33s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  98%|██████▊| 273/279 [10:34<00:13,  2.32s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  98%|██████▊| 274/279 [10:36<00:11,  2.32s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 275/279 [10:37<00:09,  2.32s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 276/279 [10:38<00:06,  2.31s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24:  99%|██████▉| 277/279 [10:40<00:04,  2.31s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24: 100%|██████▉| 278/279 [10:41<00:02,  2.31s/it, loss=0.566, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:37:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 24: 100%|███████| 279/279 [10:42<00:00,  2.30s/it, loss=0.566, v_num=0-00]\u001b[A\n",
      "Epoch 24: 100%|███████| 279/279 [10:42<00:00,  2.30s/it, loss=0.566, v_num=0-00]Epoch 24, global step 6700: 'val_loss' was not in top 3\n",
      "Epoch 25:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.555, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 03:47:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:47:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:47:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:47:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:47:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:48:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.555, v_num=0-00][NeMo W 2022-12-25 03:48:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 275/279 [10:33<00:09,  2.31s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:48:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:48:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:48:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.555, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:48:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 25: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.555, v_num=0-00]\u001b[A\n",
      "Epoch 25: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.555, v_num=0-00]Epoch 25, global step 6968: 'val_loss' was not in top 3\n",
      "Epoch 26:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.541, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 03:58:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.541, v_num=0-00]\u001b[A[NeMo W 2022-12-25 03:58:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 26: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.541, v_num=0-00]\u001b[A\n",
      "Epoch 26: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.541, v_num=0-00]Epoch 26, global step 7236: 'val_loss' was not in top 3\n",
      "Epoch 27:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.547, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 04:09:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.547, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:09:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 27: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.547, v_num=0-00]\u001b[A\n",
      "Epoch 27: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.547, v_num=0-00]Epoch 27, global step 7504: 'val_loss' was not in top 3\n",
      "Epoch 28:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.529, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 04:19:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:19:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:19:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:19:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:19:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:20:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:20:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:20:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:20:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:20:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:20:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 28: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.529, v_num=0-00]\u001b[A\n",
      "Epoch 28: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.529, v_num=0-00]Epoch 28, global step 7772: 'val_loss' was not in top 3\n",
      "Epoch 29:  96%|██████▋| 268/279 [10:31<00:25,  2.36s/it, loss=0.525, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 04:30:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  96%|██████▋| 269/279 [10:33<00:23,  2.36s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|██████▊| 270/279 [10:35<00:21,  2.35s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|██████▊| 271/279 [10:36<00:18,  2.35s/it, loss=0.525, v_num=0-00][NeMo W 2022-12-25 04:30:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  97%|██████▊| 272/279 [10:37<00:16,  2.35s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  98%|██████▊| 273/279 [10:39<00:14,  2.34s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  98%|██████▊| 274/279 [10:40<00:11,  2.34s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|██████▉| 275/279 [10:41<00:09,  2.33s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|██████▉| 276/279 [10:43<00:06,  2.33s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29:  99%|██████▉| 277/279 [10:44<00:04,  2.33s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29: 100%|██████▉| 278/279 [10:45<00:02,  2.32s/it, loss=0.525, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:30:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 29: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.525, v_num=0-00]\u001b[A\n",
      "Epoch 29: 100%|███████| 279/279 [10:47<00:00,  2.32s/it, loss=0.525, v_num=0-00]Epoch 29, global step 8040: 'val_loss' was not in top 3\n",
      "Epoch 30:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.529, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 04:41:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  97%|██████▊| 270/279 [10:30<00:21,  2.33s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  97%|██████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  97%|██████▊| 272/279 [10:32<00:16,  2.33s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  98%|██████▊| 273/279 [10:34<00:13,  2.32s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  98%|██████▊| 274/279 [10:35<00:11,  2.32s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  99%|██████▉| 275/279 [10:36<00:09,  2.32s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  99%|██████▉| 276/279 [10:38<00:06,  2.31s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30:  99%|██████▉| 277/279 [10:39<00:04,  2.31s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30: 100%|██████▉| 278/279 [10:40<00:02,  2.30s/it, loss=0.529, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:41:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 30: 100%|███████| 279/279 [10:42<00:00,  2.30s/it, loss=0.529, v_num=0-00]\u001b[A\n",
      "Epoch 30: 100%|███████| 279/279 [10:42<00:00,  2.30s/it, loss=0.529, v_num=0-00]Epoch 30, global step 8308: 'val_loss' was not in top 3\n",
      "Epoch 31:  96%|██████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.519, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 04:52:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  96%|██████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  97%|██████▊| 271/279 [10:27<00:18,  2.31s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  98%|██████▊| 274/279 [10:31<00:11,  2.30s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31:  99%|██████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31: 100%|██████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.519, v_num=0-00]\u001b[A[NeMo W 2022-12-25 04:52:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 31: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.519, v_num=0-00]\u001b[A\n",
      "Epoch 31: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.519, v_num=0-00]Epoch 31, global step 8576: 'val_loss' was not in top 3\n",
      "Epoch 32:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.516, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 05:02:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:54 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.516, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:02:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 32: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.516, v_num=0-00]\u001b[A\n",
      "Epoch 32: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.516, v_num=0-00]Epoch 32, global step 8844: 'val_loss' was not in top 3\n",
      "Epoch 33:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.512, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 05:13:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  97%|██████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.512, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:13:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 33: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.512, v_num=0-00]\u001b[A\n",
      "Epoch 33: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.512, v_num=0-00]Epoch 33, global step 9112: 'val_loss' was not in top 3\n",
      "Epoch 34:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.503, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 05:24:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.503, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:24:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 34: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.503, v_num=0-00]\u001b[A\n",
      "Epoch 34: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.503, v_num=0-00]Epoch 34, global step 9380: 'val_loss' was not in top 3\n",
      "Epoch 35:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.496, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 05:34:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:41 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.496, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:34:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 35: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.496, v_num=0-00]\u001b[A\n",
      "Epoch 35: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.496, v_num=0-00]Epoch 35, global step 9648: 'val_loss' was not in top 3\n",
      "Epoch 36:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.478, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 05:45:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  97%|██████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:25 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  99%|██████▉| 275/279 [10:33<00:09,  2.31s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.478, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:45:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 36: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.478, v_num=0-00]\u001b[A\n",
      "Epoch 36: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.478, v_num=0-00]Epoch 36, global step 9916: 'val_loss' was not in top 3\n",
      "Epoch 37:  96%|██████▋| 268/279 [10:23<00:25,  2.32s/it, loss=0.463, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 05:55:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  96%|██████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.463, v_num=0-00]\u001b[A[NeMo W 2022-12-25 05:56:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 37: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.463, v_num=0-00]\u001b[A\n",
      "Epoch 37: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.463, v_num=0-00]Epoch 37, global step 10184: 'val_loss' was not in top 3\n",
      "Epoch 38:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.454, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  96%|██████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.454, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:06:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 38:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  97%|██████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  98%|██████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  99%|██████▉| 276/279 [10:33<00:06,  2.29s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38:  99%|██████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38: 100%|██████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.454, v_num=0-00]\u001b[A\n",
      "Epoch 38: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.454, v_num=0-00]Epoch 38, global step 10452: 'val_loss' was not in top 3\n",
      "Epoch 39:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.464, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  96%|██████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.464, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:17:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39:  97%|██████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.464, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:17:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.464, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:17:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39:  98%|██████▊| 274/279 [10:31<00:11,  2.30s/it, loss=0.464, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:17:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 39:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39:  99%|██████▉| 276/279 [10:33<00:06,  2.30s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39:  99%|██████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39: 100%|██████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.464, v_num=0-00]\u001b[A\n",
      "Epoch 39: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.464, v_num=0-00]Epoch 39, global step 10720: 'val_loss' reached 7.32707 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=7.3271-epoch=39.ckpt' as top 3\n",
      "Epoch 40:  96%|███████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.44, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 06:27:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  96%|███████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:27:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  97%|███████▋| 270/279 [10:26<00:20,  2.32s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:27:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  97%|███████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:27:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  97%|███████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.44, v_num=0-00]\u001b[A\n",
      "Epoch 40:  98%|███████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:28:00 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  98%|███████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:28:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  99%|███████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:28:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  99%|███████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:28:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40:  99%|███████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:28:05 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40: 100%|███████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.44, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:28:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 40: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.44, v_num=0-00]\u001b[A\n",
      "Epoch 40: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.44, v_num=0-00]Epoch 40, global step 10988: 'val_loss' was not in top 3\n",
      "Epoch 41:  96%|██████▋| 268/279 [10:23<00:25,  2.32s/it, loss=0.444, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 06:38:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  96%|██████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.444, v_num=0-00]\u001b[A\n",
      "Epoch 41:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.444, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:38:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  97%|██████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.444, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:38:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.444, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:38:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.444, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:38:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  98%|██████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.444, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:38:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.444, v_num=0-00]\u001b[A\n",
      "Epoch 41:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.444, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:38:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 41:  99%|██████▉| 277/279 [10:35<00:04,  2.30s/it, loss=0.444, v_num=0-00]\u001b[A\n",
      "Epoch 41: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.444, v_num=0-00]\u001b[A\n",
      "Epoch 41: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.444, v_num=0-00]\u001b[A\n",
      "Epoch 41: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.444, v_num=0-00]\u001b[AEpoch 41, global step 11256: 'val_loss' reached 7.09777 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=7.0978-epoch=41.ckpt' as top 3\n",
      "Epoch 42:  96%|██████▋| 268/279 [10:25<00:25,  2.34s/it, loss=0.434, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 06:49:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.434, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:49:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.434, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:49:18 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42:  98%|██████▊| 274/279 [10:34<00:11,  2.31s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.434, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:49:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 42:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.434, v_num=0-00]\u001b[A\n",
      "Epoch 42: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.434, v_num=0-00]Epoch 42, global step 11524: 'val_loss' was not in top 3\n",
      "Epoch 43:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.418, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 06:59:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.418, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:59:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.418, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:59:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  97%|██████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.418, v_num=0-00]\u001b[A[NeMo W 2022-12-25 06:59:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  97%|██████▊| 272/279 [10:32<00:16,  2.33s/it, loss=0.418, v_num=0-00]\u001b[A\n",
      "Epoch 43:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.418, v_num=0-00]\u001b[A\n",
      "Epoch 43:  98%|██████▊| 274/279 [10:34<00:11,  2.32s/it, loss=0.418, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:00:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43:  99%|██████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.418, v_num=0-00]\u001b[A\n",
      "Epoch 43:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.418, v_num=0-00]\u001b[A\n",
      "Epoch 43:  99%|██████▉| 277/279 [10:38<00:04,  2.31s/it, loss=0.418, v_num=0-00]\u001b[A\n",
      "Epoch 43: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.418, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:00:08 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 43: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.418, v_num=0-00]\u001b[A\n",
      "Epoch 43: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.418, v_num=0-00]Epoch 43, global step 11792: 'val_loss' reached 7.19851 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=7.1985-epoch=43.ckpt' as top 3\n",
      "Epoch 44:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.419, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.419, v_num=0-00]\u001b[A\n",
      "Epoch 44:  97%|██████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  97%|██████▊| 272/279 [10:32<00:16,  2.33s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:43 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  98%|██████▊| 274/279 [10:35<00:11,  2.32s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  99%|██████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.419, v_num=0-00]\u001b[A\n",
      "Epoch 44:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44:  99%|██████▉| 277/279 [10:39<00:04,  2.31s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:49 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44: 100%|██████▉| 278/279 [10:40<00:02,  2.30s/it, loss=0.419, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:10:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 44: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.419, v_num=0-00]\u001b[A\n",
      "Epoch 44: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.419, v_num=0-00]Epoch 44, global step 12060: 'val_loss' was not in top 3\n",
      "Epoch 45:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.408, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 07:21:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  96%|██████▋| 269/279 [10:28<00:23,  2.33s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:22 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:24 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.408, v_num=0-00][NeMo W 2022-12-25 07:21:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  98%|██████▊| 274/279 [10:34<00:11,  2.32s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 45:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45:  99%|██████▉| 277/279 [10:38<00:04,  2.31s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:21:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 45: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 45: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.408, v_num=0-00]Epoch 45, global step 12328: 'val_loss' was not in top 3\n",
      "Epoch 46:  96%|███████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.42, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 07:32:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  96%|███████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:03 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  97%|███████▋| 270/279 [10:30<00:21,  2.33s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  97%|███████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  97%|███████▊| 272/279 [10:32<00:16,  2.33s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:07 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  98%|███████▊| 273/279 [10:34<00:13,  2.32s/it, loss=0.42, v_num=0-00]\u001b[A\n",
      "Epoch 46:  98%|███████▊| 274/279 [10:35<00:11,  2.32s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  99%|███████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  99%|███████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:12 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46:  99%|███████▉| 277/279 [10:39<00:04,  2.31s/it, loss=0.42, v_num=0-00]\u001b[A\n",
      "Epoch 46: 100%|███████▉| 278/279 [10:40<00:02,  2.30s/it, loss=0.42, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:32:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 46: 100%|████████| 279/279 [10:41<00:00,  2.30s/it, loss=0.42, v_num=0-00]\u001b[A\n",
      "Epoch 46: 100%|████████| 279/279 [10:41<00:00,  2.30s/it, loss=0.42, v_num=0-00]Epoch 46, global step 12596: 'val_loss' was not in top 3\n",
      "Epoch 47:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.408, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:42:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  97%|██████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:42:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  97%|██████▊| 272/279 [10:32<00:16,  2.32s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47:  98%|██████▊| 274/279 [10:34<00:11,  2.32s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.408, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:42:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 47:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47:  99%|██████▉| 277/279 [10:38<00:04,  2.30s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.408, v_num=0-00]\u001b[A\n",
      "Epoch 47: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.408, v_num=0-00]Epoch 47, global step 12864: 'val_loss' reached 6.84073 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=6.8407-epoch=47.ckpt' as top 3\n",
      "Epoch 48:  96%|██████▋| 268/279 [10:25<00:25,  2.34s/it, loss=0.412, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.412, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:53:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.412, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:53:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.412, v_num=0-00]\u001b[A[NeMo W 2022-12-25 07:53:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 48:  98%|██████▊| 274/279 [10:34<00:11,  2.31s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.412, v_num=0-00]\u001b[A\n",
      "Epoch 48: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.412, v_num=0-00]Epoch 48, global step 13132: 'val_loss' was not in top 3\n",
      "Epoch 49:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.428, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.428, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:04:06 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.428, v_num=0-00]\u001b[A\n",
      "Epoch 49:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.428, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:04:09 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.428, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:04:10 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.428, v_num=0-00]\u001b[A\n",
      "Epoch 49:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.428, v_num=0-00]\u001b[A\n",
      "Epoch 49:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.428, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:04:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.428, v_num=0-00]\u001b[A\n",
      "Epoch 49:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.428, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:04:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.428, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:04:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 49: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.428, v_num=0-00]\u001b[A\n",
      "Epoch 49: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.428, v_num=0-00]\u001b[AEpoch 49, global step 13400: 'val_loss' was not in top 3\n",
      "Epoch 50:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.402, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 08:14:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:47 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:51 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.402, v_num=0-00]\u001b[A\n",
      "Epoch 50:  98%|██████▊| 274/279 [10:34<00:11,  2.31s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50:  99%|██████▉| 277/279 [10:38<00:04,  2.30s/it, loss=0.402, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:14:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 50: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.402, v_num=0-00]\u001b[A\n",
      "Epoch 50: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.402, v_num=0-00]\u001b[A\n",
      "Epoch 50: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.402, v_num=0-00]Epoch 50, global step 13668: 'val_loss' was not in top 3\n",
      "Epoch 51:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.405, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.405, v_num=0-00]\u001b[A\n",
      "Epoch 51:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.405, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:25:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.405, v_num=0-00]\u001b[A\n",
      "Epoch 51:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.405, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:25:31 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.405, v_num=0-00]\u001b[A\n",
      "Epoch 51:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.405, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:25:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.405, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:25:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  99%|██████▉| 276/279 [10:36<00:06,  2.30s/it, loss=0.405, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:25:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.405, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:25:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 51: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.405, v_num=0-00]\u001b[A\n",
      "Epoch 51: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.405, v_num=0-00]\u001b[A\n",
      "Epoch 51: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.405, v_num=0-00]Epoch 51, global step 13936: 'val_loss' was not in top 3\n",
      "Epoch 52:  96%|███████▋| 268/279 [10:25<00:25,  2.34s/it, loss=0.39, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  96%|███████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52:  97%|███████▋| 270/279 [10:29<00:20,  2.33s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52:  97%|███████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:36:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  97%|███████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52:  98%|███████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:36:14 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52:  98%|███████▊| 274/279 [10:34<00:11,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52:  99%|███████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52:  99%|███████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52:  99%|███████▉| 277/279 [10:38<00:04,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:36:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52: 100%|███████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:36:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 52: 100%|████████| 279/279 [10:40<00:00,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 52: 100%|████████| 279/279 [10:40<00:00,  2.30s/it, loss=0.39, v_num=0-00]\u001b[AEpoch 52, global step 14204: 'val_loss' reached 6.93636 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=6.9364-epoch=52.ckpt' as top 3\n",
      "Epoch 53:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.392, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.392, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:46:52 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.392, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:46:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 53:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.392, v_num=0-00]\u001b[A\n",
      "Epoch 53: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.392, v_num=0-00]Epoch 53, global step 14472: 'val_loss' reached 6.70976 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=6.7098-epoch=53.ckpt' as top 3\n",
      "Epoch 54:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.399, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  96%|██████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.399, v_num=0-00]\u001b[A\n",
      "Epoch 54:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:29 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  97%|██████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:33 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  98%|██████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.399, v_num=0-00][NeMo W 2022-12-25 08:57:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.399, v_num=0-00]\u001b[A\n",
      "Epoch 54:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:37 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54:  99%|██████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.399, v_num=0-00]\u001b[A[NeMo W 2022-12-25 08:57:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 54: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.399, v_num=0-00]\u001b[A\n",
      "Epoch 54: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.399, v_num=0-00]Epoch 54, global step 14740: 'val_loss' was not in top 3\n",
      "Epoch 55:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.388, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55:  97%|██████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.388, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:08:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.388, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:08:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.388, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:08:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 55: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.388, v_num=0-00]\u001b[A\n",
      "Epoch 55: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.388, v_num=0-00]Epoch 55, global step 15008: 'val_loss' was not in top 3\n",
      "Epoch 56:  96%|███████▋| 268/279 [10:21<00:25,  2.32s/it, loss=0.39, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  96%|███████▋| 269/279 [10:23<00:23,  2.32s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  97%|███████▋| 270/279 [10:24<00:20,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  97%|███████▊| 271/279 [10:25<00:18,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  97%|███████▊| 272/279 [10:27<00:16,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:18:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 56:  98%|███████▊| 273/279 [10:28<00:13,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  98%|███████▊| 274/279 [10:29<00:11,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  99%|███████▉| 275/279 [10:30<00:09,  2.29s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  99%|███████▉| 276/279 [10:31<00:06,  2.29s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56:  99%|███████▉| 277/279 [10:33<00:04,  2.29s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56: 100%|███████▉| 278/279 [10:34<00:02,  2.28s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56: 100%|████████| 279/279 [10:35<00:00,  2.28s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 56: 100%|████████| 279/279 [10:35<00:00,  2.28s/it, loss=0.39, v_num=0-00]Epoch 56, global step 15276: 'val_loss' was not in top 3\n",
      "Epoch 57:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.389, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.389, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:29:23 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57:  98%|██████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.389, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:29:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 57:  99%|██████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57: 100%|██████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 57: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.389, v_num=0-00]Epoch 57, global step 15544: 'val_loss' was not in top 3\n",
      "Epoch 58:  96%|██████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.385, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  96%|██████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  97%|██████▊| 270/279 [10:25<00:20,  2.32s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  97%|██████▊| 271/279 [10:26<00:18,  2.31s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  97%|██████▊| 272/279 [10:27<00:16,  2.31s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  98%|██████▊| 273/279 [10:29<00:13,  2.30s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  98%|██████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  99%|██████▉| 275/279 [10:31<00:09,  2.30s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  99%|██████▉| 276/279 [10:32<00:06,  2.29s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58:  99%|██████▉| 277/279 [10:33<00:04,  2.29s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58: 100%|██████▉| 278/279 [10:34<00:02,  2.28s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58: 100%|███████| 279/279 [10:35<00:00,  2.28s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 58: 100%|███████| 279/279 [10:35<00:00,  2.28s/it, loss=0.385, v_num=0-00]Epoch 58, global step 15812: 'val_loss' was not in top 3\n",
      "Epoch 59:  96%|███████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.39, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 09:50:36 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59:  96%|███████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:50:38 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59:  97%|███████▋| 270/279 [10:28<00:20,  2.33s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:50:39 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59:  97%|███████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 59:  97%|███████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:50:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59:  98%|███████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 59:  98%|███████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:50:44 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59:  99%|███████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:50:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59:  99%|███████▉| 276/279 [10:36<00:06,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 59:  99%|███████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A[NeMo W 2022-12-25 09:50:48 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 59: 100%|███████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 59: 100%|████████| 279/279 [10:39<00:00,  2.29s/it, loss=0.39, v_num=0-00]\u001b[A\n",
      "Epoch 59: 100%|████████| 279/279 [10:39<00:00,  2.29s/it, loss=0.39, v_num=0-00]Epoch 59, global step 16080: 'val_loss' was not in top 3\n",
      "Epoch 60:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.393, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.393, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:01:19 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 60:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60:  99%|██████▉| 277/279 [10:35<00:04,  2.30s/it, loss=0.393, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:01:27 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 60: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.393, v_num=0-00]\u001b[A\n",
      "Epoch 60: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.393, v_num=0-00]Epoch 60, global step 16348: 'val_loss' was not in top 3\n",
      "Epoch 61:  96%|███████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.38, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  96%|███████▋| 269/279 [10:25<00:23,  2.32s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  97%|███████▋| 270/279 [10:26<00:20,  2.32s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  97%|███████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  97%|███████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  98%|███████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  98%|███████▊| 274/279 [10:31<00:11,  2.30s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  99%|███████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  99%|███████▉| 276/279 [10:33<00:06,  2.29s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61:  99%|███████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.38, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:12:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 61: 100%|███████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61: 100%|████████| 279/279 [10:36<00:00,  2.28s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 61: 100%|████████| 279/279 [10:36<00:00,  2.28s/it, loss=0.38, v_num=0-00]Epoch 61, global step 16616: 'val_loss' was not in top 3\n",
      "Epoch 62:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.379, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.379, v_num=0-00]\u001b[A\n",
      "Epoch 62: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.379, v_num=0-00]Epoch 62, global step 16884: 'val_loss' was not in top 3\n",
      "Epoch 63:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.385, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.385, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:33:13 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 63:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.385, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:33:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 63:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.385, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:33:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 63:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.385, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:33:21 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 63:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.385, v_num=0-00]\u001b[A\n",
      "Epoch 63: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.385, v_num=0-00]Epoch 63, global step 17152: 'val_loss' was not in top 3\n",
      "Epoch 64:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.384, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 10:43:50 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 64:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.384, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:43:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 64:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.384, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:43:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 64:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.384, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:43:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 64:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.384, v_num=0-00]\u001b[A[NeMo W 2022-12-25 10:43:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 64:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.384, v_num=0-00]\u001b[A\n",
      "Epoch 64: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.384, v_num=0-00]Epoch 64, global step 17420: 'val_loss' was not in top 3\n",
      "Epoch 65:  96%|███████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.38, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  96%|███████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  97%|███████▋| 270/279 [10:26<00:20,  2.32s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  97%|███████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  97%|███████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  98%|███████▊| 273/279 [10:29<00:13,  2.31s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  98%|███████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  99%|███████▉| 275/279 [10:31<00:09,  2.30s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  99%|███████▉| 276/279 [10:32<00:06,  2.29s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65:  99%|███████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65: 100%|███████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65: 100%|████████| 279/279 [10:36<00:00,  2.28s/it, loss=0.38, v_num=0-00]\u001b[A\n",
      "Epoch 65: 100%|████████| 279/279 [10:36<00:00,  2.28s/it, loss=0.38, v_num=0-00]Epoch 65, global step 17688: 'val_loss' was not in top 3\n",
      "Epoch 66:  96%|██████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.377, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  96%|██████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  97%|██████▊| 270/279 [10:25<00:20,  2.32s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  97%|██████▊| 271/279 [10:27<00:18,  2.31s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  98%|██████▊| 273/279 [10:29<00:13,  2.31s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  98%|██████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  99%|██████▉| 275/279 [10:31<00:09,  2.30s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  99%|██████▉| 276/279 [10:33<00:06,  2.29s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66:  99%|██████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66: 100%|██████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 66: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.377, v_num=0-00]Epoch 66, global step 17956: 'val_loss' was not in top 3\n",
      "Epoch 67:  96%|██████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.376, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  96%|██████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67:  97%|██████▊| 270/279 [10:25<00:20,  2.32s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67:  97%|██████▊| 271/279 [10:26<00:18,  2.31s/it, loss=0.376, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:15:45 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 67:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.376, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:15:46 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 67:  98%|██████▊| 273/279 [10:29<00:13,  2.31s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67:  98%|██████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67:  99%|██████▉| 276/279 [10:33<00:06,  2.29s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67:  99%|██████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.376, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:15:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 67: 100%|██████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67: 100%|███████| 279/279 [10:37<00:00,  2.28s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 67: 100%|███████| 279/279 [10:37<00:00,  2.28s/it, loss=0.376, v_num=0-00]Epoch 67, global step 18224: 'val_loss' was not in top 3\n",
      "Epoch 68:  96%|██████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.375, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  96%|██████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  97%|██████▊| 270/279 [10:25<00:20,  2.32s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  97%|██████▊| 271/279 [10:26<00:18,  2.31s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  98%|██████▊| 273/279 [10:29<00:13,  2.30s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  98%|██████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  99%|██████▉| 275/279 [10:31<00:09,  2.30s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  99%|██████▉| 276/279 [10:32<00:06,  2.29s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68:  99%|██████▉| 277/279 [10:33<00:04,  2.29s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68: 100%|██████▉| 278/279 [10:34<00:02,  2.28s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68: 100%|███████| 279/279 [10:35<00:00,  2.28s/it, loss=0.375, v_num=0-00]\u001b[A\n",
      "Epoch 68: 100%|███████| 279/279 [10:35<00:00,  2.28s/it, loss=0.375, v_num=0-00]Epoch 68, global step 18492: 'val_loss' was not in top 3\n",
      "Epoch 69:  96%|██████▋| 268/279 [10:22<00:25,  2.32s/it, loss=0.378, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 11:36:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 69:  96%|██████▋| 269/279 [10:24<00:23,  2.32s/it, loss=0.378, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:36:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 69:  97%|██████▊| 270/279 [10:25<00:20,  2.32s/it, loss=0.378, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:36:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 69:  97%|██████▊| 271/279 [10:26<00:18,  2.31s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69:  97%|██████▊| 272/279 [10:28<00:16,  2.31s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69:  98%|██████▊| 273/279 [10:29<00:13,  2.30s/it, loss=0.378, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:37:01 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 69:  98%|██████▊| 274/279 [10:30<00:11,  2.30s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69:  99%|██████▉| 275/279 [10:31<00:09,  2.30s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69:  99%|██████▉| 276/279 [10:32<00:06,  2.29s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69:  99%|██████▉| 277/279 [10:33<00:04,  2.29s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69: 100%|██████▉| 278/279 [10:35<00:02,  2.28s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.378, v_num=0-00]\u001b[A\n",
      "Epoch 69: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.378, v_num=0-00]Epoch 69, global step 18760: 'val_loss' was not in top 3\n",
      "Epoch 70:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.374, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  97%|██████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  98%|██████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70:  99%|██████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70: 100%|██████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.374, v_num=0-00]\u001b[A\n",
      "Epoch 70: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.374, v_num=0-00]Epoch 70, global step 19028: 'val_loss' was not in top 3\n",
      "Epoch 71:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.389, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.389, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:58:15 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 71:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.389, v_num=0-00]\u001b[A[NeMo W 2022-12-25 11:58:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 71:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71:  98%|██████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71:  99%|██████▉| 277/279 [10:35<00:04,  2.30s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.389, v_num=0-00]\u001b[A\n",
      "Epoch 71: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.389, v_num=0-00]Epoch 71, global step 19296: 'val_loss' was not in top 3\n",
      "Epoch 72:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.376, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.376, v_num=0-00]\u001b[A[NeMo W 2022-12-25 12:08:57 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 72:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.376, v_num=0-00]\u001b[A\n",
      "Epoch 72: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.376, v_num=0-00]Epoch 72, global step 19564: 'val_loss' reached 6.80678 (best 6.65369), saving model to '/home/aifree910884/TTS/nemo_experiments/Tacotron2/2022-12-24_23-00-00/checkpoints/Tacotron2--val_loss=6.8068-epoch=72.ckpt' as top 3\n",
      "Epoch 73:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.369, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A[NeMo W 2022-12-25 12:19:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A[NeMo W 2022-12-25 12:19:40 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 73:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 73: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.369, v_num=0-00]Epoch 73, global step 19832: 'val_loss' was not in top 3\n",
      "Epoch 74:  96%|██████▋| 268/279 [10:30<00:25,  2.35s/it, loss=0.369, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  96%|██████▋| 269/279 [10:32<00:23,  2.35s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  97%|██████▊| 270/279 [10:33<00:21,  2.35s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  97%|██████▊| 271/279 [10:34<00:18,  2.34s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  97%|██████▊| 272/279 [10:36<00:16,  2.34s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  98%|██████▊| 273/279 [10:37<00:14,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  98%|██████▊| 274/279 [10:38<00:11,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  99%|██████▉| 275/279 [10:39<00:09,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  99%|██████▉| 276/279 [10:40<00:06,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74:  99%|██████▉| 277/279 [10:41<00:04,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74: 100%|██████▉| 278/279 [10:42<00:02,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74: 100%|███████| 279/279 [10:44<00:00,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 74: 100%|███████| 279/279 [10:44<00:00,  2.31s/it, loss=0.369, v_num=0-00]Epoch 74, global step 20100: 'val_loss' was not in top 3\n",
      "Epoch 75:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.377, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.377, v_num=0-00]\u001b[A\n",
      "Epoch 75: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.377, v_num=0-00]Epoch 75, global step 20368: 'val_loss' was not in top 3\n",
      "Epoch 76:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.369, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  99%|██████▉| 275/279 [10:33<00:09,  2.31s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.369, v_num=0-00]\u001b[A\n",
      "Epoch 76: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.369, v_num=0-00]Epoch 76, global step 20636: 'val_loss' was not in top 3\n",
      "Epoch 77:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.367, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.367, v_num=0-00]\u001b[A[NeMo W 2022-12-25 13:02:16 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 77:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.367, v_num=0-00]\u001b[A\n",
      "Epoch 77: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.367, v_num=0-00]Epoch 77, global step 20904: 'val_loss' was not in top 3\n",
      "Epoch 78:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.364, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  96%|██████▋| 269/279 [10:28<00:23,  2.33s/it, loss=0.364, v_num=0-00]\u001b[A[NeMo W 2022-12-25 13:12:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 78:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.364, v_num=0-00]\u001b[A\n",
      "Epoch 78: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.364, v_num=0-00]Epoch 78, global step 21172: 'val_loss' was not in top 3\n",
      "Epoch 79:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.365, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  99%|██████▉| 275/279 [10:33<00:09,  2.31s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.365, v_num=0-00]\u001b[A\n",
      "Epoch 79: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.365, v_num=0-00]\u001b[AEpoch 79, global step 21440: 'val_loss' was not in top 3\n",
      "Epoch 80:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.361, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 80: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.361, v_num=0-00]Epoch 80, global step 21708: 'val_loss' was not in top 3\n",
      "Epoch 81:  96%|██████▋| 268/279 [10:27<00:25,  2.34s/it, loss=0.357, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  96%|██████▋| 269/279 [10:29<00:23,  2.34s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  97%|██████▊| 270/279 [10:30<00:21,  2.34s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  97%|██████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  97%|██████▊| 272/279 [10:32<00:16,  2.33s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  98%|██████▊| 273/279 [10:34<00:13,  2.32s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  98%|██████▊| 274/279 [10:35<00:11,  2.32s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  99%|██████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81:  99%|██████▉| 277/279 [10:38<00:04,  2.31s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.357, v_num=0-00]\u001b[A\n",
      "Epoch 81: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.357, v_num=0-00]Epoch 81, global step 21976: 'val_loss' was not in top 3\n",
      "Epoch 82:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.355, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.355, v_num=0-00]\u001b[A[NeMo W 2022-12-25 13:55:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 82:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  99%|██████▉| 275/279 [10:33<00:09,  2.31s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 82: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.355, v_num=0-00]Epoch 82, global step 22244: 'val_loss' was not in top 3\n",
      "Epoch 83:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.359, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  97%|██████▊| 271/279 [10:30<00:18,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 83: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.359, v_num=0-00]Epoch 83, global step 22512: 'val_loss' was not in top 3\n",
      "Epoch 84:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.359, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 14:16:58 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 14:17:02 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 14:17:04 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 84: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 84: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.359, v_num=0-00]Epoch 84, global step 22780: 'val_loss' was not in top 3\n",
      "Epoch 85:  96%|███████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.36, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  96%|███████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  97%|███████▋| 270/279 [10:28<00:20,  2.33s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  97%|███████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  97%|███████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  98%|███████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  98%|███████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  99%|███████▉| 275/279 [10:33<00:09,  2.31s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  99%|███████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85:  99%|███████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85: 100%|███████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.36, v_num=0-00]\u001b[A\n",
      "Epoch 85: 100%|████████| 279/279 [10:38<00:00,  2.29s/it, loss=0.36, v_num=0-00]Epoch 85, global step 23048: 'val_loss' was not in top 3\n",
      "Epoch 86:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.363, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  98%|██████▊| 274/279 [10:31<00:11,  2.30s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  99%|██████▉| 276/279 [10:33<00:06,  2.29s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86:  99%|██████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86: 100%|██████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.363, v_num=0-00]\u001b[A\n",
      "Epoch 86: 100%|███████| 279/279 [10:36<00:00,  2.28s/it, loss=0.363, v_num=0-00]Epoch 86, global step 23316: 'val_loss' was not in top 3\n",
      "Epoch 87:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.356, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  97%|██████▊| 270/279 [10:27<00:20,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 87: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.356, v_num=0-00]Epoch 87, global step 23584: 'val_loss' was not in top 3\n",
      "Epoch 88:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.356, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 88: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.356, v_num=0-00]Epoch 88, global step 23852: 'val_loss' was not in top 3\n",
      "Epoch 89:  96%|██████▋| 268/279 [10:26<00:25,  2.34s/it, loss=0.356, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  96%|██████▋| 269/279 [10:28<00:23,  2.34s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89:  97%|██████▊| 270/279 [10:30<00:21,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:10:11 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  97%|██████▊| 271/279 [10:31<00:18,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89:  97%|██████▊| 272/279 [10:32<00:16,  2.33s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89:  98%|██████▊| 274/279 [10:35<00:11,  2.32s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89:  99%|██████▉| 275/279 [10:36<00:09,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:10:17 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89:  99%|██████▉| 276/279 [10:37<00:06,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89:  99%|██████▉| 277/279 [10:38<00:04,  2.31s/it, loss=0.356, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:10:20 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 89: 100%|██████▉| 278/279 [10:40<00:02,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.356, v_num=0-00]\u001b[A\n",
      "Epoch 89: 100%|███████| 279/279 [10:41<00:00,  2.30s/it, loss=0.356, v_num=0-00]Epoch 89, global step 24120: 'val_loss' was not in top 3\n",
      "Epoch 90:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.361, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90:  97%|██████▊| 270/279 [10:27<00:20,  2.32s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90:  97%|██████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90:  97%|██████▊| 272/279 [10:29<00:16,  2.32s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.361, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:20:55 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.361, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:20:56 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90:  99%|██████▉| 277/279 [10:35<00:04,  2.30s/it, loss=0.361, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:20:59 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 90: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.361, v_num=0-00]\u001b[A\n",
      "Epoch 90: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.361, v_num=0-00]\u001b[AEpoch 90, global step 24388: 'val_loss' was not in top 3\n",
      "Epoch 91:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.352, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91:  97%|██████▊| 270/279 [10:27<00:20,  2.33s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.352, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:31:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.352, v_num=0-00]\u001b[A[NeMo W 2022-12-25 15:31:35 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 91:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 91: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.352, v_num=0-00]Epoch 91, global step 24656: 'val_loss' was not in top 3\n",
      "Epoch 92:  96%|██████▋| 268/279 [10:23<00:25,  2.33s/it, loss=0.355, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  96%|██████▋| 269/279 [10:25<00:23,  2.33s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  97%|██████▊| 270/279 [10:26<00:20,  2.32s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  97%|██████▊| 271/279 [10:27<00:18,  2.32s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  97%|██████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  98%|██████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  98%|██████▊| 274/279 [10:31<00:11,  2.30s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  99%|██████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  99%|██████▉| 276/279 [10:33<00:06,  2.30s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92:  99%|██████▉| 277/279 [10:34<00:04,  2.29s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92: 100%|██████▉| 278/279 [10:35<00:02,  2.29s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92: 100%|███████| 279/279 [10:37<00:00,  2.28s/it, loss=0.355, v_num=0-00]\u001b[A\n",
      "Epoch 92: 100%|███████| 279/279 [10:37<00:00,  2.28s/it, loss=0.355, v_num=0-00]Epoch 92, global step 24924: 'val_loss' was not in top 3\n",
      "Epoch 93:  96%|███████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.35, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  96%|███████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  97%|███████▋| 270/279 [10:27<00:20,  2.32s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  97%|███████▊| 271/279 [10:28<00:18,  2.32s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  97%|███████▊| 272/279 [10:29<00:16,  2.31s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  98%|███████▊| 273/279 [10:30<00:13,  2.31s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  98%|███████▊| 274/279 [10:31<00:11,  2.31s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  99%|███████▉| 275/279 [10:32<00:09,  2.30s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  99%|███████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93:  99%|███████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93: 100%|███████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93: 100%|████████| 279/279 [10:37<00:00,  2.28s/it, loss=0.35, v_num=0-00]\u001b[A\n",
      "Epoch 93: 100%|████████| 279/279 [10:37<00:00,  2.28s/it, loss=0.35, v_num=0-00]Epoch 93, global step 25192: 'val_loss' was not in top 3\n",
      "Epoch 94:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.359, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 16:03:26 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 16:03:28 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  98%|██████▊| 273/279 [10:33<00:13,  2.32s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94:  98%|██████▊| 274/279 [10:34<00:11,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 16:03:30 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94:  99%|██████▉| 275/279 [10:35<00:09,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94:  99%|██████▉| 276/279 [10:36<00:06,  2.31s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94:  99%|██████▉| 277/279 [10:37<00:04,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A[NeMo W 2022-12-25 16:03:34 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 94: 100%|██████▉| 278/279 [10:39<00:02,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.359, v_num=0-00]\u001b[A\n",
      "Epoch 94: 100%|███████| 279/279 [10:40<00:00,  2.30s/it, loss=0.359, v_num=0-00]Epoch 94, global step 25460: 'val_loss' was not in top 3\n",
      "Epoch 95:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.351, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 95: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.351, v_num=0-00]Epoch 95, global step 25728: 'val_loss' was not in top 3\n",
      "Epoch 96:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.346, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A[NeMo W 2022-12-25 16:24:42 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.346, v_num=0-00]\u001b[A[NeMo W 2022-12-25 16:24:53 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 96: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.346, v_num=0-00]\u001b[A\n",
      "Epoch 96: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.346, v_num=0-00]Epoch 96, global step 25996: 'val_loss' was not in top 3\n",
      "Epoch 97:  96%|██████▋| 268/279 [10:24<00:25,  2.33s/it, loss=0.351, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  96%|██████▋| 269/279 [10:26<00:23,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97:  99%|██████▉| 277/279 [10:35<00:04,  2.29s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97: 100%|██████▉| 278/279 [10:36<00:02,  2.29s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 97: 100%|███████| 279/279 [10:37<00:00,  2.29s/it, loss=0.351, v_num=0-00]Epoch 97, global step 26264: 'val_loss' was not in top 3\n",
      "Epoch 98:  96%|██████▋| 268/279 [10:25<00:25,  2.34s/it, loss=0.351, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  97%|██████▊| 270/279 [10:29<00:20,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  97%|██████▊| 271/279 [10:30<00:18,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  97%|██████▊| 272/279 [10:31<00:16,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  98%|██████▊| 273/279 [10:32<00:13,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  98%|██████▊| 274/279 [10:33<00:11,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  99%|██████▉| 275/279 [10:34<00:09,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  99%|██████▉| 276/279 [10:35<00:06,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98:  99%|██████▉| 277/279 [10:36<00:04,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98: 100%|██████▉| 278/279 [10:38<00:02,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 98: 100%|███████| 279/279 [10:39<00:00,  2.29s/it, loss=0.351, v_num=0-00]Epoch 98, global step 26532: 'val_loss' was not in top 3\n",
      "Epoch 99:  96%|██████▋| 268/279 [10:25<00:25,  2.33s/it, loss=0.352, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  96%|██████▋| 269/279 [10:27<00:23,  2.33s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  97%|██████▊| 270/279 [10:28<00:20,  2.33s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  97%|██████▊| 271/279 [10:29<00:18,  2.32s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  97%|██████▊| 272/279 [10:30<00:16,  2.32s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  98%|██████▊| 273/279 [10:31<00:13,  2.31s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  98%|██████▊| 274/279 [10:32<00:11,  2.31s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  99%|██████▉| 275/279 [10:33<00:09,  2.30s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  99%|██████▉| 276/279 [10:34<00:06,  2.30s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99:  99%|██████▉| 277/279 [10:35<00:04,  2.30s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99: 100%|██████▉| 278/279 [10:37<00:02,  2.29s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.352, v_num=0-00]\u001b[A\n",
      "Epoch 99: 100%|███████| 279/279 [10:38<00:00,  2.29s/it, loss=0.352, v_num=0-00]Epoch 99, global step 26800: 'val_loss' was not in top 3\n",
      "Epoch 100:  96%|█████▊| 268/279 [10:27<00:25,  2.34s/it, loss=0.351, v_num=0-00]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                        | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                           | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 100:  96%|█████▊| 269/279 [10:29<00:23,  2.34s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  97%|█████▊| 270/279 [10:31<00:21,  2.34s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  97%|█████▊| 271/279 [10:32<00:18,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  97%|█████▊| 272/279 [10:33<00:16,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  98%|█████▊| 273/279 [10:34<00:13,  2.33s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  98%|█████▉| 274/279 [10:35<00:11,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  99%|█████▉| 275/279 [10:37<00:09,  2.32s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  99%|█████▉| 276/279 [10:38<00:06,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100:  99%|█████▉| 277/279 [10:39<00:04,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A[NeMo W 2022-12-25 17:07:32 tacotron2:341] Reached max decoder steps 1000.\n",
      "\n",
      "Epoch 100: 100%|█████▉| 278/279 [10:41<00:02,  2.31s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100: 100%|██████| 279/279 [10:42<00:00,  2.30s/it, loss=0.351, v_num=0-00]\u001b[A\n",
      "Epoch 100: 100%|██████| 279/279 [10:42<00:00,  2.30s/it, loss=0.351, v_num=0-00]Epoch 100, global step 27068: 'val_loss' was not in top 3\n",
      "Epoch 101:  82%|████▉ | 229/279 [08:53<01:56,  2.33s/it, loss=0.346, v_num=0-00]"
     ]
    }
   ],
   "source": [
    "!(python tacotron2.py \\\n",
    "  train_dataset=trn_dataset_LJ.json \\\n",
    "  validation_datasets=val_dataset_LJ.json \\\n",
    "  trainer.max_epochs=200 \\\n",
    "  trainer.accelerator=null \\\n",
    "  trainer.check_val_every_n_epoch=1 \\\n",
    " +trainer.gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a5bd3",
   "metadata": {},
   "source": [
    "## 3.2 Load pre-train model and finetune for a new speaker\n",
    "* 若有額外 Dataset 則可參考 [Fastpitch Finetune Finetune](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/FastPitch_Finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317a4a2d",
   "metadata": {},
   "source": [
    "# 4. 推論\n",
    "* 此部分請參考[Text_to_Speech_for_Google_Colab](https://github.com/AI-FREE-Team/TTS-AIGO/blob/main/Text_to_Speech.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f505a49",
   "metadata": {},
   "source": [
    "# 5. 應用於原住民族語音生成的部份成果\n",
    "* 此部分請參考[Text_to_Speech_for_Google_Colab](https://github.com/AI-FREE-Team/TTS-AIGO/blob/main/Text_to_Speech.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae06ee",
   "metadata": {},
   "source": [
    "# 6. 引用(Reference)\n",
    "* [Nvidia Nemo](https://github.com/NVIDIA/NeMo/tree/main/examples/tts)\n",
    "* **[1 Ref]** [Nemo TTS Primer](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/NeMo_TTS_Primer.ipynb)\n",
    "* **[2.2 Ref]** [Text Normalization Tutorial](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/text_processing/Text_(Inverse)_Normalization.ipynb#scrollTo=LvBfrQVybleF)\n",
    "* **[3.0 Ref]** [Tacotron 2 Training](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/Tacotron2_Training.ipynb)\n",
    "* **[3.2 Ref]** [Finetuning FastPitch for a new speaker](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/FastPitch_Finetuning.ipynb)\n",
    "* **[4.1 Ref]** [Model Select](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/Inference_ModelSelect.ipynb)\n",
    "* **[4.1 Ref]** [Tacotron2 LJSpeech Overview](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tacotron2_ljspeech)\n",
    "* **[5 Ref]** [原住民族語E樂園](https://web.klokah.tw/essay/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
